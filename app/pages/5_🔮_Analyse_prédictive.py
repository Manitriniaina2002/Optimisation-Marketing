"""
Page d'analyse pr√©dictive pour l'application d'analyse marketing.
Permet de r√©aliser des pr√©dictions sur le comportement des clients et la valeur √† vie.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys
import traceback
from datetime import datetime, timedelta
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, 
    roc_auc_score, confusion_matrix, classification_report, roc_curve, auc
)
# from xgboost import XGBClassifier  # lazy-imported when selected
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.preprocessing import label_binarize

# Ajouter le r√©pertoire parent au chemin pour les imports
sys.path.append(str(Path(__file__).parent.parent))

from utils.visualization import plot_confusion_matrix, plot_feature_importance
from utils.analysis import MarketingAnalyzer
from config import APP_CONFIG

# Configuration de la page
st.set_page_config(
    page_title=f"{APP_CONFIG['app_name']} - Analyse pr√©dictive",
    page_icon="üîÆ",
    layout="wide"
)

# Titre de la page
st.title("üîÆ Analyse pr√©dictive")
st.markdown("---")

# V√©rifier que les donn√©es sont charg√©es
if 'data_loaded' not in st.session_state or not st.session_state.data_loaded:
    st.warning("Veuillez d'abord importer et valider les donn√©es dans l'onglet 'Importation des donn√©es'.")
    st.stop()

# R√©cup√©rer les donn√©es de la session
customers_df = st.session_state.get('customers_df')
orders_df = st.session_state.get('orders_df')
marketing_df = st.session_state.get('marketing_df')

# Travailler sur une copie pour √©viter les SettingWithCopyWarning
if customers_df is not None:
    customers_df = customers_df.copy()

# V√©rifier que les donn√©es n√©cessaires sont disponibles
if customers_df is None or orders_df is None:
    st.error("Les donn√©es clients et/ou commandes sont manquantes. Veuillez importer les donn√©es n√©cessaires.")
    st.stop()

# Initialiser l'analyseur marketing
if 'analyzer' not in st.session_state:
    st.session_state.analyzer = MarketingAnalyzer({
        'customers': customers_df,
        'orders': orders_df,
        'marketing': marketing_df if marketing_df is not None else pd.DataFrame()
    })

# Section de pr√©paration des donn√©es
with st.expander("üìä Pr√©paration des donn√©es", expanded=True):
    st.markdown("""
    ### üõ†Ô∏è Configuration de l'analyse pr√©dictive
    
    Cette section vous permet de configurer votre analyse pr√©dictive en s√©lectionnant les variables pertinentes
    et en d√©finissant les param√®tres de pr√©paration des donn√©es.
    """)
    
    # Indicateur visuel d'√©tape
    st.progress(0.2, text="√âtape 1/4 - Configuration de l'analyse")
    
    # V√©rifier si les segments sont disponibles
    if 'rfm_data' not in st.session_state or 'segment' not in st.session_state.rfm_data.columns:
        st.warning("Veuvez d'abord effectuer la segmentation des clients dans l'onglet pr√©c√©dent.")
        st.stop()
    
    # Pr√©parer les donn√©es pour la mod√©lisation
    st.subheader("S√©lection des variables")
    
    # D√©tection robuste des variables num√©riques
    numeric_cols = []
    for col in customers_df.columns:
        if col == 'customer_id':
            continue
            
        # V√©rifier si la colonne est d√©j√† num√©rique
        if pd.api.types.is_numeric_dtype(customers_df[col]):
            numeric_cols.append(col)
        # Sinon, essayer de convertir en num√©rique
        else:
            try:
                # Essayer de convertir en num√©rique
                pd.to_numeric(customers_df[col], errors='raise')
                numeric_cols.append(col)
                # Convertir la colonne en num√©rique
                customers_df[col] = pd.to_numeric(customers_df[col], errors='coerce')
            except (ValueError, TypeError):
                pass  # La colonne n'est pas num√©rique
    
    # D√©tection des variables cat√©gorielles
    categorical_cols = []
    for col in customers_df.columns:
        if col in numeric_cols or col == 'customer_id':
            continue
            
        # Si la colonne a un nombre limit√© de valeurs uniques, la consid√©rer comme cat√©gorielle
        unique_ratio = customers_df[col].nunique() / len(customers_df)
        if unique_ratio < 0.5:  # Moins de 50% de valeurs uniques
            categorical_cols.append(col)
    
    # Afficher un avertissement si aucune variable num√©rique n'est d√©tect√©e
    if not numeric_cols:
        st.warning("‚ö†Ô∏è Aucune variable num√©rique d√©tect√©e. V√©rifiez le format de vos donn√©es.")
        
        # Afficher les types de donn√©es d√©tect√©s pour le d√©bogage (version compatible Arrow)
        st.write("Types de donn√©es d√©tect√©s dans le DataFrame :")
        try:
            dtypes_str = customers_df.dtypes.astype(str)
            dtypes_df = pd.DataFrame({
                'Colonne': dtypes_str.index,
                'Type': dtypes_str.values
            })
            st.dataframe(dtypes_df, use_container_width=True)
        except Exception:
            st.write({col: str(dt) for col, dt in customers_df.dtypes.items()})
        
        # Afficher un √©chantillon des donn√©es
        st.write("Aper√ßu des donn√©es :")
        st.dataframe(customers_df.head())
    
    # Afficher les colonnes d√©tect√©es pour le d√©bogage
    st.session_state.debug_numeric_cols = numeric_cols
    st.session_state.debug_categorical_cols = categorical_cols
    
    # Afficher les colonnes d√©tect√©es (en mode d√©bogage)
    with st.expander("üîç D√©tection des colonnes (d√©bogage)", expanded=False):
        st.write("Colonnes num√©riques d√©tect√©es :", numeric_cols)
        st.write("Colonnes cat√©gorielles d√©tect√©es :", categorical_cols)
        st.write("Types de donn√©es :")
        try:
            dtypes_str = customers_df.dtypes.astype(str)
            dtypes_df = pd.DataFrame({
                'Colonne': dtypes_str.index,
                'Type': dtypes_str.values
            })
            st.dataframe(dtypes_df, use_container_width=True)
        except Exception:
            st.write({col: str(dt) for col, dt in customers_df.dtypes.items()})
    
    # S√©lection des variables pour la mod√©lisation
    selected_numeric = st.multiselect(
        "Variables num√©riques",
        options=numeric_cols,
        default=numeric_cols[:3] if len(numeric_cols) > 0 else [],
        help="S√©lectionnez les variables num√©riques √† inclure dans le mod√®le"
    )
    
    selected_categorical = st.multiselect(
        "Variables cat√©gorielles",
        options=categorical_cols,
        default=categorical_cols[:2] if len(categorical_cols) > 0 else [],
        help="S√©lectionnez les variables cat√©gorielles √† inclure dans le mod√®le"
    )
    
    # S√©lection de la variable cible
    target_options = ['segment']  # Par d√©faut, on pr√©dit le segment
    
    # Ajouter d'autres options de cible si disponibles
    if 'churn' in customers_df.columns:
        target_options.append('churn')
    if 'lifetime_value' in customers_df.columns:
        target_options.append('lifetime_value')
    
    target_variable = st.selectbox(
        "Variable cible",
        options=target_options,
        index=0,
        help="S√©lectionnez la variable √† pr√©dire"
    )
    
    # Options de pr√©traitement
    st.subheader("Options de pr√©traitement")
    
    col1, col2 = st.columns(2)
    
    with col1:
        handle_missing = st.selectbox(
            "Gestion des valeurs manquantes",
            options=["Supprimer les lignes", "Remplacer par la m√©diane/mode", "Imputer avec KNN"],
            index=1
        )
        
        scale_features = st.checkbox(
            "Mettre √† l'√©chelle les variables num√©riques",
            value=True,
            help="Standardiser les variables num√©riques (moyenne=0, √©cart-type=1)"
        )
    
    with col2:
        test_size = st.slider(
            "Taille de l'ensemble de test",
            min_value=0.1,
            max_value=0.5,
            value=0.2,
            step=0.05,
            help="Proportion des donn√©es √† utiliser pour le test"
        )
        
        random_state = st.number_input(
            "Graine al√©atoire",
            min_value=0,
            max_value=100,
            value=42,
            help="Pour la reproductibilit√© des r√©sultats"
        )
    
    # Bouton pour pr√©parer les donn√©es
    if st.button("Pr√©parer les donn√©es", type="primary"):
        with st.spinner("Pr√©paration des donn√©es en cours..."):
            try:
                # Fusionner les donn√©es RFM avec les donn√©es clients
                rfm_data = st.session_state.rfm_data
                
                # V√©rifier que les colonnes n√©cessaires sont pr√©sentes dans rfm_data
                required_rfm_columns = ['customer_id', 'recency', 'frequency', 'monetary_value', 'segment']
                missing_rfm_cols = [col for col in required_rfm_columns if col not in rfm_data.columns]
                if missing_rfm_cols:
                    st.error(f"Colonnes manquantes dans les donn√©es RFM : {', '.join(missing_rfm_cols)}")
                    st.stop()
                
                # S√©lectionner les colonnes n√©cessaires
                features = ['customer_id'] + selected_numeric + selected_categorical
                
                # V√©rifier que les colonnes s√©lectionn√©es existent dans customers_df
                missing_cols = [col for col in features if col not in customers_df.columns]
                if missing_cols:
                    st.error(f"Colonnes manquantes dans les donn√©es clients : {', '.join(missing_cols)}")
                    st.stop()
                
                # V√©rifier le type de la colonne customer_id dans les deux DataFrames
                if rfm_data['customer_id'].dtype != customers_df['customer_id'].dtype:
                    st.warning("Les types de la colonne 'customer_id' diff√®rent entre les donn√©es RFM et clients. Conversion en type commun...")
                    rfm_data['customer_id'] = rfm_data['customer_id'].astype(str)
                    customers_df['customer_id'] = customers_df['customer_id'].astype(str)
                
                # Cr√©er le jeu de donn√©es complet
                try:
                    model_data = pd.merge(
                        rfm_data[required_rfm_columns],
                        customers_df[features],
                        on='customer_id',
                        how='left'
                    )
                except Exception as e:
                    st.error(f"Erreur lors de la fusion des donn√©es RFM et clients : {e}")
                    st.error(f"Types de colonnes dans rfm_data: {rfm_data[required_rfm_columns].dtypes}")
                    st.error(f"Types de colonnes dans customers_df: {customers_df[features].dtypes}")
                    st.stop()
                
                # G√©rer les valeurs manquantes
                if handle_missing == "Supprimer les lignes":
                    model_data = model_data.dropna()
                elif handle_missing == "Remplacer par la m√©diane/mode":
                    for col in selected_numeric:
                        if col in model_data.columns and model_data[col].isnull().any():
                            model_data[col] = model_data[col].fillna(model_data[col].median())
                    
                    for col in selected_categorical:
                        if col in model_data.columns and model_data[col].isnull().any():
                            model_data[col] = model_data[col].fillna(model_data[col].mode()[0])
                
                # Encoder les variables cat√©gorielles
                label_encoders = {}
                for col in selected_categorical:
                    if col in model_data.columns:
                        le = LabelEncoder()
                        model_data[col] = le.fit_transform(model_data[col].astype(str))
                        label_encoders[col] = le
                
                # Pr√©parer les caract√©ristiques et la cible
                X = model_data[['recency', 'frequency', 'monetary_value'] + selected_numeric + selected_categorical]
                y = model_data[target_variable]
                
                # Mettre √† l'√©chelle les variables num√©riques si demand√©
                scaler = None
                if scale_features and len(selected_numeric) > 0:
                    scaler = StandardScaler()
                    X[selected_numeric] = scaler.fit_transform(X[selected_numeric])
                
                # Diviser les donn√©es en ensembles d'entra√Ænement et de test
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=random_state, stratify=y if len(y.unique()) > 1 else None
                )
                
                # Enregistrer les donn√©es pr√©par√©es dans la session
                st.session_state.model_data = {
                    'X_train': X_train,
                    'X_test': X_test,
                    'y_train': y_train,
                    'y_test': y_test,
                    'feature_names': X.columns.tolist(),
                    'target_name': target_variable,
                    'label_encoders': label_encoders,
                    'scaler': scaler,
                    'preprocessing': {
                        'handle_missing': handle_missing,
                        'scale_features': scale_features,
                        'test_size': test_size,
                        'random_state': random_state
                    }
                }
                
                st.success(f"Donn√©es pr√©par√©es avec succ√®s pour la pr√©diction de {target_variable}!")
                st.write(f"- Nombre d'√©chantillons d'entra√Ænement : {len(X_train)}")
                st.write(f"- Nombre d'√©chantillons de test : {len(X_test)}")
                st.write(f"- Nombre de caract√©ristiques : {len(X_train.columns)}")
                
                # Afficher un aper√ßu des donn√©es pr√©par√©es
                st.subheader("Aper√ßu des donn√©es pr√©par√©es")
                st.dataframe(pd.concat([X_train.head(), y_train.head()], axis=1))
                
            except Exception as e:
                st.error(f"Erreur lors de la pr√©paration des donn√©es : {e}")

# V√©rifier si les donn√©es sont pr√©par√©es
if 'model_data' not in st.session_state:
    st.warning("Veuvez d'abord pr√©parer les donn√©es dans la section ci-dessus.")
    st.stop()

# Section de mod√©lisation
with st.expander("ü§ñ Entra√Ænement du mod√®le", expanded=False):
    st.markdown("""
    ### üéØ Entra√Ænement du mod√®le
    
    Configurez et entra√Ænez un mod√®le de machine learning pour effectuer des pr√©dictions sur vos donn√©es.
    Comparez les performances de diff√©rents algorithmes et param√®tres.
    """)
    
    # Indicateur visuel d'√©tape
    st.progress(0.5, text="√âtape 2/4 - Entra√Ænement du mod√®le")
    
    # S√©lection du mod√®le
    model_type = st.selectbox(
        "Type de mod√®le",
        options=["For√™t al√©atoire", "Gradient Boosting", "XGBoost"],
        index=0,
        help="S√©lectionnez l'algorithme de machine learning √† utiliser"
    )
    
    # Param√®tres du mod√®le
    st.subheader("Param√®tres du mod√®le")
    
    col1, col2 = st.columns(2)
    
    with col1:
        n_estimators = st.slider(
            "Nombre d'arbres",
            min_value=10,
            max_value=500,
            value=100,
            step=10,
            help="Nombre d'arbres dans la for√™t ou d'estimateurs"
        )
        
        max_depth = st.slider(
            "Profondeur maximale",
            min_value=1,
            max_value=20,
            value=5,
            help="Profondeur maximale de chaque arbre"
        )
    
    with col2:
        min_samples_split = st.slider(
            "Nombre minimum d'√©chantillons pour diviser un n≈ìud",
            min_value=2,
            max_value=20,
            value=2,
            help="Nombre minimum d'√©chantillons requis pour diviser un n≈ìud interne"
        )
        
        min_samples_leaf = st.slider(
            "Nombre minimum d'√©chantillons par feuille",
            min_value=1,
            max_value=10,
            value=1,
            help="Nombre minimum d'√©chantillons requis pour √™tre dans un n≈ìud feuille"
        )
    
    # Options d'entra√Ænement
    st.subheader("Options d'entra√Ænement")
    
    use_cross_validation = st.checkbox(
        "Utiliser la validation crois√©e",
        value=True,
        help="√âvalue le mod√®le avec une validation crois√©e sur l'ensemble d'entra√Ænement"
    )
    
    cv_folds = st.slider(
        "Nombre de plis pour la validation crois√©e",
        min_value=3,
        max_value=10,
        value=5,
        disabled=not use_cross_validation
    )
    
    # Bouton pour lancer l'entra√Ænement
    if st.button("Entra√Æner le mod√®le", type="primary"):
        with st.spinner("Entra√Ænement du mod√®le en cours..."):
            try:
                # R√©cup√©rer les donn√©es pr√©par√©es
                model_data = st.session_state.model_data
                X_train = model_data['X_train']
                X_test = model_data['X_test']
                y_train = model_data['y_train']
                y_test = model_data['y_test']
                
                # Initialiser le mod√®le s√©lectionn√©
                if model_type == "For√™t al√©atoire":
                    model = RandomForestClassifier(
                        n_estimators=n_estimators,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        min_samples_leaf=min_samples_leaf,
                        random_state=model_data['preprocessing']['random_state'],
                        n_jobs=-1,
                        verbose=0
                    )
                elif model_type == "Gradient Boosting":
                    model = GradientBoostingClassifier(
                        n_estimators=n_estimators,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        min_samples_leaf=min_samples_leaf,
                        random_state=model_data['preprocessing']['random_state'],
                        verbose=0
                    )
                else:  # XGBoost
                    try:
                        from xgboost import XGBClassifier  # lazy import
                        model = XGBClassifier(
                            n_estimators=n_estimators,
                            max_depth=max_depth,
                            min_child_weight=min_samples_leaf,
                            subsample=0.8,
                            colsample_bytree=0.8,
                            random_state=model_data['preprocessing']['random_state'],
                            n_jobs=-1,
                            verbosity=0
                        )
                    except Exception as e:
                        st.error("XGBoost n'est pas disponible dans cet environnement.")
                        st.info("S√©lectionnez 'For√™t al√©atoire' ou 'Gradient Boosting', ou ajoutez 'xgboost' aux requirements si n√©cessaire.")
                        st.stop()
                
                # Entra√Æner le mod√®le
                model.fit(X_train, y_train)
                
                # Faire des pr√©dictions sur l'ensemble de test
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test) if hasattr(model, "predict_proba") else None
                
                # Calculer les m√©triques d'√©valuation
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, average='weighted')
                recall = recall_score(y_test, y_pred, average='weighted')
                f1 = f1_score(y_test, y_pred, average='weighted')
                
                # Calculer l'AUC-ROC si possible (classification binaire ou multiclasse avec probabilit√©s)
                if y_pred_proba is not None and len(np.unique(y_test)) == 2:
                    auc_roc = roc_auc_score(y_test, y_pred_proba[:, 1])
                elif y_pred_proba is not None and len(np.unique(y_test)) > 2:
                    # Pour la classification multiclasse, on peut calculer l'AUC-ROC moyenn√©
                    try:
                        auc_roc = roc_auc_score(
                            pd.get_dummies(y_test), 
                            y_pred_proba,
                            multi_class='ovr',
                            average='weighted'
                        )
                    except:
                        auc_roc = None
                else:
                    auc_roc = None
                
                # Enregistrer le mod√®le et les r√©sultats dans la session
                st.session_state.trained_model = {
                    'model': model,
                    'model_type': model_type,
                    'metrics': {
                        'accuracy': accuracy,
                        'precision': precision,
                        'recall': recall,
                        'f1': f1,
                        'auc_roc': auc_roc
                    },
                    'predictions': {
                        'y_test': y_test,
                        'y_pred': y_pred,
                        'y_pred_proba': y_pred_proba
                    },
                    'feature_importances': dict(zip(
                        model_data['feature_names'],
                        model.feature_importances_
                    )) if hasattr(model, 'feature_importances_') else None
                }
                
                st.success("Mod√®le entra√Æn√© avec succ√®s !")
                
                # Afficher les m√©triques d'√©valuation
                st.subheader("Performances du mod√®le")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Exactitude (Accuracy)", f"{accuracy:.3f}")
                
                with col2:
                    st.metric("Pr√©cision", f"{precision:.3f}")
                
                with col3:
                    st.metric("Rappel", f"{recall:.3f}")
                
                with col4:
                    st.metric("Score F1", f"{f1:.3f}")
                
                # Affichage am√©lior√© des m√©triques
                st.markdown("### D√©tail des performances")
                
                # Cr√©ation d'un tableau de m√©triques
                metrics_df = pd.DataFrame({
                    'M√©trique': ['Pr√©cision', 'Rappel', 'F1-Score', 'Exactitude'],
                    'Valeur': [precision, recall, f1, accuracy],
                    'Description': [
                        'Capacit√© √† ne pas classer √† tort un client comme positif',
                        'Capacit√© √† trouver tous les clients positifs',
                        'Moyenne harmonique entre pr√©cision et rappel',
                        'Pourcentage de pr√©dictions correctes'
                    ]
                })
                
                # Afficher le tableau des m√©triques
                st.dataframe(
                    metrics_df,
                    column_config={
                        'M√©trique': st.column_config.TextColumn('M√©trique'),
                        'Valeur': st.column_config.ProgressColumn(
                            'Valeur',
                            format='%.3f',
                            min_value=0,
                            max_value=1
                        ),
                        'Description': st.column_config.TextColumn('Description')
                    },
                    hide_index=True,
                    use_container_width=True
                )
                
                # Affichage de la courbe ROC si les probabilit√©s sont disponibles
                if hasattr(model, 'predict_proba'):
                    try:
                        # Obtenir les probabilit√©s de pr√©diction
                        y_pred_proba = model.predict_proba(X_test)
                        classes_ = getattr(model, 'classes_', np.unique(y_test))
                        n_classes = len(classes_)
                        
                        st.markdown("### Courbe ROC")
                        
                        if n_classes == 2:
                            # Cas binaire
                            # Identifier l'index de la classe positive (on prend la 2e classe par convention)
                            pos_index = 1 if y_pred_proba.shape[1] > 1 else 0
                            fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, pos_index], pos_label=classes_[pos_index])
                            roc_auc = auc(fpr, tpr)
                            
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {roc_auc:.3f})', line=dict(color='#3498db', width=2)))
                            fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Al√©atoire', line=dict(color='#95a5a6', width=1, dash='dash')))
                            fig.update_layout(title='Courbe ROC', xaxis_title='Taux de faux positifs', yaxis_title='Taux de vrais positifs', showlegend=True, height=500)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            # Cas multi-classes: One-vs-Rest
                            y_test_bin = label_binarize(y_test, classes=classes_)
                            fig = go.Figure()
                            for i, cls in enumerate(classes_):
                                try:
                                    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
                                    roc_auc = auc(fpr, tpr)
                                    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'Classe {cls} (AUC = {roc_auc:.3f})'))
                                except Exception:
                                    continue
                            fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Al√©atoire', line=dict(color='#95a5a6', width=1, dash='dash')))
                            fig.update_layout(title='Courbes ROC (One-vs-Rest)', xaxis_title='Taux de faux positifs', yaxis_title='Taux de vrais positifs', showlegend=True, height=500)
                            st.plotly_chart(fig, use_container_width=True)
                    except Exception as e:
                        st.warning(f"Impossible d'afficher la courbe ROC : {str(e)}")
                
                # Affichage de l'importance des caract√©ristiques
                st.markdown("### Importance des caract√©ristiques")
                
                try:
                    # R√©cup√©rer l'importance des caract√©ristiques
                    if hasattr(model, 'feature_importances_'):
                        importances = model.feature_importances_
                        feature_importance = pd.DataFrame({
                            'Caract√©ristique': X_train.columns,
                            'Importance': importances
                        }).sort_values('Importance', ascending=False)
                        
                        # Afficher le graphique d'importance
                        fig = px.bar(
                            feature_importance.head(10),
                            x='Importance',
                            y='Caract√©ristique',
                            orientation='h',
                            title='Top 10 des caract√©ristiques les plus importantes',
                            labels={'Importance': 'Importance', 'Caract√©ristique': 'Caract√©ristique'},
                            color='Importance',
                            color_continuous_scale='Blues'
                        )
                        
                        fig.update_layout(
                            height=400,
                            showlegend=False,
                            xaxis_title='Importance',
                            yaxis_title='Caract√©ristique',
                            yaxis={'categoryorder': 'total ascending'}
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Afficher la matrice de confusion
                    st.markdown("### Matrice de confusion")
                    
                    classes_ = np.unique(y_test)
                    cm = confusion_matrix(y_test, y_pred, labels=classes_)
                    fig = px.imshow(
                        cm,
                        labels=dict(x="Pr√©dit", y="R√©el", color="Nombre"),
                        x=[str(c) for c in classes_],
                        y=[str(c) for c in classes_],
                        text_auto=True,
                        aspect="auto",
                        color_continuous_scale='Blues'
                    )
                    
                    fig.update_layout(
                        title='Matrice de confusion',
                        xaxis_title='Pr√©diction',
                        yaxis_title='V√©rit√© terrain',
                        coloraxis_showscale=False
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Interpr√©tation des r√©sultats
                    st.markdown("### Interpr√©tation des r√©sultats")
                    
                    st.markdown("""
                    **Comment interpr√©ter ces r√©sultats ?**
                    
                    - **Pr√©cision √©lev√©e** : Lorsque le mod√®le pr√©dit une classe, il a une forte probabilit√© d'avoir raison.
                    - **Rappel √©lev√©** : Le mod√®le identifie bien la plupart des cas positifs.
                    - **F1-Score** : Bon √©quilibre entre pr√©cision et rappel (1 = parfait).
                    - **AUC-ROC** : Capacit√© du mod√®le √† distinguer les classes (1 = parfait).
                    
                    **Recommandations :**
                    - Si la pr√©cision est faible, le mod√®le fait trop de faux positifs.
                    - Si le rappel est faible, le mod√®le manque trop de vrais positifs.
                    - Si les deux sont bas, le mod√®le doit √™tre am√©lior√© ou les donn√©es mieux pr√©par√©es.
                    """)
                    
                except Exception as e:
                    st.warning(f"Impossible d'afficher certaines visualisations : {str(e)}")
                
                # Afficher la matrice de confusion
                st.subheader("Matrice de confusion")
                
                # Cr√©er la figure de la matrice de confusion avec l'utilitaire (corrige l'appel)
                classes_ = np.unique(y_test)
                cm = confusion_matrix(y_test, y_pred, labels=classes_)
                fig_cm = plot_confusion_matrix(
                    cm,
                    class_names=[str(c) for c in classes_],
                    title=f"Matrice de confusion - {model_type}"
                )
                
                st.plotly_chart(fig_cm, use_container_width=True)
                
                # Afficher le rapport de classification
                st.subheader("Rapport de classification")
                
                # G√©n√©rer le rapport de classification
                report = classification_report(
                    y_test, 
                    y_pred, 
                    target_names=[f"Classe {label}" for label in np.unique(y_test)],
                    output_dict=True
                )
                
                # Convertir en DataFrame pour un affichage plus propre
                report_df = pd.DataFrame(report).transpose()
                st.dataframe(report_df, use_container_width=True)
                
                # Afficher l'importance des caract√©ristiques si disponible
                if st.session_state.trained_model['feature_importances'] is not None:
                    st.subheader("Importance des caract√©ristiques")
                    
                    # Cr√©er un graphique d'importance des caract√©ristiques
                    fig_importance = plot_feature_importance(
                        st.session_state.trained_model['feature_importances'],
                        title=f"Importance des caract√©ristiques - {model_type}"
                    )
                    
                    st.plotly_chart(fig_importance, use_container_width=True)
                
            except Exception as e:
                st.error(f"Erreur lors de l'entra√Ænement du mod√®le : {e}")

# V√©rifier si un mod√®le est entra√Æn√©
if 'trained_model' not in st.session_state:
    st.warning("Veuvez d'abord entra√Æner un mod√®le dans la section ci-dessus.")
    st.stop()

# Section de pr√©diction
with st.expander(" Faire des pr√©dictions", expanded=False):
    st.markdown("""
    ### Effectuer des pr√©dictions
    
    Utilisez le mod√®le entra√Æn√© pour effectuer des pr√©dictions sur de nouvelles donn√©es
    ou sur un √©chantillon de test pour √©valuer ses performances.
    """)
    
    # Indicateur visuel d'√©tape
    st.progress(0.8, text="√âtape 3/4 - Pr√©dictions")
    
    # R√©cup√©rer le mod√®le et les donn√©es
    model_data = st.session_state.model_data
    trained_model = st.session_state.trained_model
    model = trained_model['model']
    
    # Options de pr√©diction
    prediction_type = st.radio(
        "Type de pr√©diction",
        ["Sur un √©chantillon de test", "Sur de nouvelles donn√©es"],
        horizontal=True,
        help="Choisissez de tester le mod√®le sur des donn√©es de test ou de faire des pr√©dictions sur de nouvelles entr√©es"
    )
    
    # Ajout d'un s√©parateur visuel
    st.markdown("---")
    
    # Aide contextuelle
    with st.expander(" Comment utiliser cette section", expanded=False):
        st.markdown("""
        **Pr√©dictions sur √©chantillon de test**
        - Le mod√®le est √©valu√© sur des donn√©es qu'il n'a jamais vues pendant l'entra√Ænement
        - Permet d'estimer les performances r√©elles du mod√®le
        
        **Pr√©dictions sur nouvelles donn√©es**
        - Saisissez manuellement les valeurs pour chaque caract√©ristique
        - Obtenez une pr√©diction instantan√©e
        - Parfait pour tester des sc√©narios sp√©cifiques
        """)
    
    if prediction_type == "Sur un √©chantillon de test":
        # R√©cup√©rer les donn√©es de test
        X_test = model_data['X_test']
        y_test = model_data['y_test']
        
        # Nombre d'√©chantillons √† afficher
        max_samples = min(50, len(X_test))
        min_samples = min(5, max_samples)  # S'assurer que min_samples <= max_samples
        
        if max_samples > 0:
            sample_size = st.slider(
                "Nombre d'√©chantillons √† afficher",
                min_value=1,
                max_value=max(1, max_samples),
                value=min(10, max_samples),
                step=1
            )
        else:
            st.warning("Aucun √©chantillon disponible pour l'affichage.")
            st.stop()
        
        # Faire des pr√©dictions
        with st.spinner("Pr√©diction en cours..."):
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
            
            # Calculer les m√©triques
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')
            f1 = f1_score(y_test, y_pred, average='weighted')
        
        # Afficher les r√©sultats
        st.subheader(" R√©sultats sur l'√©chantillon de test")
        
        # Afficher les m√©triques dans des colonnes
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Exactitude", f"{accuracy:.2%}")
        with col2:
            st.metric("Pr√©cision", f"{precision:.2%}")
        with col3:
            st.metric("Rappel", f"{recall:.2%}")
        with col4:
            st.metric("Score F1", f"{f1:.2%}")
        
        # Afficher un √©chantillon des pr√©dictions
        st.markdown(f"### Aper√ßu des pr√©dictions ({sample_size} √©chantillons)")
        
        # S√©lection al√©atoire d'√©chantillons
        sample_indices = np.random.choice(len(X_test), sample_size, replace=False)
        
        # Cr√©er un DataFrame avec les r√©sultats
        results = []
        for i in sample_indices:
            true_label = y_test.iloc[i]
            pred_label = y_pred[i]
            result = {
                'ID': i,
                'V√©rit√© terrain': str(true_label),
                'Pr√©diction': str(pred_label),
                'Statut': ' Correct' if true_label == pred_label else ' Erreur'
            }
            if y_pred_proba is not None:
                # Probabilit√© de la classe pr√©dite (ou max proba en multiclasses)
                proba = float(np.max(y_pred_proba[i]))
                result['Confiance'] = f"{proba:.1%}"
                result['_Jauge'] = proba
            results.append(result)
        
        # Cr√©er un DataFrame avec les r√©sultats
        results_df = pd.DataFrame(results)
        
        # Afficher le tableau des r√©sultats avec mise en forme conditionnelle
        st.dataframe(
            results_df,
            column_config={
                'ID': 'ID',
                'V√©rit√© terrain': st.column_config.TextColumn('V√©rit√© terrain'),
                'Pr√©diction': st.column_config.TextColumn('Pr√©diction'),
                'Statut': st.column_config.TextColumn('Statut'),
                'Confiance': st.column_config.ProgressColumn(
                    'Confiance',
                    format='%.1f%%',
                    min_value=0,
                    max_value=1,
                    help="Niveau de confiance de la pr√©diction"
                ) if 'Confiance' in results_df.columns else None,
                '_Jauge': None  # Colonne masqu√©e pour la jauge
            },
            hide_index=True,
            use_container_width=True
        )
        
        # Afficher la distribution des pr√©dictions
        st.markdown("### Distribution des pr√©dictions")
        
        # Calculer les comptes de pr√©dictions avec √©tiquettes dynamiques
        classes_pred = np.unique(y_pred)
        pred_counts = pd.Series(y_pred).value_counts().reindex(classes_pred, fill_value=0)
        labels = [str(c) for c in classes_pred]
        
        # Cr√©er un graphique √† barres
        fig = px.bar(
            x=labels,
            y=pred_counts.values,
            labels={'x': 'Classe pr√©dite', 'y': "Nombre d'√©chantillons"},
            title="Distribution des pr√©dictions sur l'ensemble de test",
            color=labels,
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        
        fig.update_layout(
            showlegend=False,
            xaxis_title='Classe pr√©dite',
            yaxis_title="Nombre d'√©chantillons",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        # Formulaire pour la saisie manuelle des caract√©ristiques
        st.subheader("Saisie des caract√©ristiques")
        
        # Cr√©er un formulaire pour chaque caract√©ristique
        input_data = {}
        
        # Ajouter les champs pour les caract√©ristiques RFM
        input_data['recency'] = st.number_input(
            "R√©cence (jours)", 
            min_value=0, 
            max_value=365*5, 
            value=30,
            help="Nombre de jours depuis le dernier achat"
        )
        
        input_data['frequency'] = st.number_input(
            "Fr√©quence", 
            min_value=1, 
            value=5,
            help="Nombre total d'achats"
        )

        # D√©finir une valeur par d√©faut pour monetary_value
        default_monetary = 100.0  # Valeur par d√©faut si rfm_data n'est pas disponible
        if 'rfm_data' in st.session_state and 'monetary_value' in st.session_state.rfm_data:
            default_monetary = float(st.session_state.rfm_data['monetary_value'].median())
        
        input_data['monetary_value'] = st.number_input(
            "Valeur mon√©taire (‚Ç¨)",
            min_value=0.0,
            value=default_monetary,
            help="Valeur mon√©taire moyenne des achats"
        )

        # Ajouter les champs pour les autres caract√©ristiques num√©riques
        for col in model_data['X_train'].columns:
            if col not in ['recency', 'frequency', 'monetary_value'] and model_data['X_train'][col].dtype in ['int64', 'float64']:
                min_val = float(model_data['X_train'][col].min())
                max_val = float(model_data['X_train'][col].max())
                mean_val = float(model_data['X_train'][col].mean())
                
                input_data[col] = st.number_input(
                    f"{col}",
                    min_value=min_val,
                    max_value=max_val,
                    value=mean_val,
                    step=(max_val - min_val) / 100 if (max_val - min_val) > 0 else 0.1
                )
        
        # Bouton pour effectuer la pr√©diction
        if st.button("Pr√©dire", type="primary"):
            try:
                # R√©cup√©rer les noms des caract√©ristiques dans le m√™me ordre que lors de l'entra√Ænement
                feature_names = model_data.get('feature_names', model_data['X_train'].columns.tolist())
                
                # Cr√©er un DataFrame vide avec les colonnes dans le bon ordre
                input_df = pd.DataFrame(columns=feature_names)
                
                # Remplir avec les valeurs du formulaire
                for col in feature_names:
                    if col in input_data:
                        # Convertir explicitement le type de donn√©es pour correspondre √† l'entra√Ænement
                        if col in model_data['X_train'].columns:
                            dtype = model_data['X_train'][col].dtype
                            if dtype == 'int64':
                                input_df[col] = [int(input_data[col])]
                            elif dtype == 'float64':
                                input_df[col] = [float(input_data[col])]
                            else:
                                input_df[col] = [input_data[col]]
                    else:
                        # Si une caract√©ristique est manquante, utiliser la m√©diane (pour les num√©riques) ou le mode (pour les cat√©gorielles)
                        if col in model_data['X_train'].columns:
                            if model_data['X_train'][col].dtype in ['int64', 'float64']:
                                input_df[col] = [float(model_data['X_train'][col].median())]
                            else:
                                input_df[col] = [model_data['X_train'][col].mode()[0]]
                
                # V√©rifier que toutes les colonnes n√©cessaires sont pr√©sentes
                missing_cols = set(feature_names) - set(input_df.columns)
                if missing_cols:
                    st.error(f"Colonnes manquantes dans les donn√©es d'entr√©e : {', '.join(missing_cols)}")
                    st.error("Veuvez r√©initialiser l'application et v√©rifier les donn√©es d'entra√Ænement.")
                    st.stop()
                
                # V√©rifier que les types de donn√©es correspondent
                for col in input_df.columns:
                    expected_dtype = model_data['X_train'][col].dtype
                    if input_df[col].dtype != expected_dtype:
                        try:
                            if expected_dtype == 'int64':
                                input_df[col] = input_df[col].astype('int64')
                            elif expected_dtype == 'float64':
                                input_df[col] = input_df[col].astype('float64')
                        except Exception as e:
                            st.error(f"Impossible de convertir la colonne {col} en {expected_dtype}: {e}")
                            st.stop()
                
                # Afficher un aper√ßu des donn√©es avant pr√©diction (pour le d√©bogage)
                st.write("### Donn√©es d'entr√©e pour la pr√©diction")
                st.dataframe(input_df[feature_names].head())
                
                # Mettre √† l'√©chelle les caract√©ristiques si n√©cessaire
                if model_data['scaler'] is not None:
                    numeric_cols = [col for col in feature_names 
                                  if model_data['X_train'][col].dtype in ['int64', 'float64']]
                    
                    # V√©rifier que toutes les colonnes num√©riques sont pr√©sentes
                    missing_numeric = [col for col in numeric_cols if col not in input_df.columns]
                    if missing_numeric:
                        st.error(f"Colonnes num√©riques manquantes pour la mise √† l'√©chelle : {', '.join(missing_numeric)}")
                        st.stop()
                    
                    # Appliquer la mise √† l'√©chelle
                    input_df[numeric_cols] = model_data['scaler'].transform(input_df[numeric_cols])
                
                # V√©rifier une derni√®re fois que toutes les colonnes attendues sont pr√©sentes
                missing_final = set(feature_names) - set(input_df.columns)
                if missing_final:
                    st.error(f"Colonnes manquantes apr√®s pr√©paration : {', '.join(missing_final)}")
                    st.stop()
                
                # R√©organiser les colonnes pour correspondre exactement √† l'ordre d'entra√Ænement
                input_df = input_df[feature_names]
                
                # Faire la pr√©diction
                prediction = model.predict(input_df)
                prediction_proba = model.predict_proba(input_df) if hasattr(model, "predict_proba") else None
                
            except Exception as e:
                st.error(f"Erreur lors de la pr√©paration des donn√©es pour la pr√©diction : {e}")
                st.error("D√©tails de l'erreur :")
                st.error(traceback.format_exc())
                st.error("\nVeuvez v√©rifier que les donn√©es d'entr√©e correspondent au format attendu par le mod√®le.")
                st.stop()
            
            # Enregistrer l'exemple de pr√©diction
            example = input_df.copy()
            example['target_predicted'] = prediction[0]
            if prediction_proba is not None:
                for i, proba in enumerate(prediction_proba[0]):
                    example[f'prob_class_{i}'] = proba
            
            st.session_state.prediction_example = example
    
    # Afficher les r√©sultats de la pr√©diction si disponible
    if 'prediction_example' in st.session_state:
        example = st.session_state.prediction_example
        
        st.subheader("R√©sultat de la pr√©diction")
        
        # Afficher la pr√©diction
        if 'target_actual' in example.columns:
            st.write(f"**Valeur r√©elle** : {example['target_actual'].iloc[0]}")
        
        st.write(f"**Pr√©diction** : {example['target_predicted'].iloc[0]}")
        
        # Afficher les probabilit√©s si disponibles
        prob_cols = [col for col in example.columns if col.startswith('prob_class_')]
        if prob_cols:
            st.subheader("Probabilit√©s par classe")
            
            # Cr√©er un graphique √† barres des probabilit√©s
            prob_values = [example[col].iloc[0] for col in prob_cols]
            prob_labels = [f"Classe {i}" for i in range(len(prob_cols))]
            
            fig_proba = px.bar(
                x=prob_labels,
                y=prob_values,
                labels={'x': 'Classe', 'y': 'Probabilit√©'},
                title="Distribution des probabilit√©s de pr√©diction",
                text=[f"{p*100:.1f}%" for p in prob_values]
            )
            
            fig_proba.update_traces(
                marker_color='#636EFA',
                textposition='outside',
                textfont_size=12
            )
            
            fig_proba.update_layout(
                yaxis=dict(range=[0, 1.1]),
                height=400
            )
            
            st.plotly_chart(fig_proba, use_container_width=True)
        
        # Afficher les caract√©ristiques d'entr√©e
        st.subheader("Caract√©ristiques d'entr√©e")
        
        # Filtrer les colonnes √† afficher
        display_cols = [col for col in example.columns if not col.startswith(('prob_class_', 'target_'))]
        
        # Afficher les caract√©ristiques dans un tableau
        st.dataframe(
            example[display_cols].T.rename(columns={0: 'Valeur'}),
            use_container_width=True
        )

# Section d'exportation du mod√®le
with st.expander("üíæ Exporter le mod√®le", expanded=False):
    st.markdown("""
    ### üì§ Exportation du mod√®le
    
    Exportez votre mod√®le entra√Æn√© pour une utilisation ult√©rieure ou pour le d√©ploiement en production.
    """)
    
    # Indicateur visuel d'√©tape
    st.progress(1.0, text="√âtape 4/4 - Exportation")
    
    # Options d'exportation
    export_format = st.selectbox(
        "Format d'exportation",
        ["Joblib (.pkl)", "ONNX", "PMML"],
        index=0
    )
    
    # Bouton pour exporter le mod√®le
    if st.button("Exporter le mod√®le", type="primary"):
        with st.spinner("Exportation en cours..."):
            try:
                # Cr√©er un fichier temporaire
                import tempfile
                import os
                
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp_file:
                    # Sauvegarder le mod√®le et les m√©tadonn√©es
                    model_data = {
                        'model': st.session_state.trained_model['model'],
                        'model_type': st.session_state.trained_model['model_type'],
                        'metrics': st.session_state.trained_model['metrics'],
                        'feature_names': st.session_state.model_data['feature_names'],
                        'target_name': st.session_state.model_data['target_name'],
                        'preprocessing': st.session_state.model_data['preprocessing']
                    }
                    
                    joblib.dump(model_data, tmp_file.name)
                    
                    # Lire le fichier pour le t√©l√©chargement
                    with open(tmp_file.name, 'rb') as f:
                        bytes_data = f.read()
                    
                    # Proposer le t√©l√©chargement
                    st.download_button(
                        label="T√©l√©charger le mod√®le",
                        data=bytes_data,
                        file_name=f"modele_{st.session_state.model_data['target_name']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl",
                        mime="application/octet-stream"
                    )
                
                # Supprimer le fichier temporaire
                os.unlink(tmp_file.name)
                
                st.success("Mod√®le export√© avec succ√®s !")
                
            except Exception as e:
                st.error(f"Erreur lors de l'exportation du mod√®le : {e}")

# Navigation entre les pages
st.markdown("---")
col1, col2, col3 = st.columns([1, 1, 1])

with col1:
    if st.button("‚Üê Pr√©c√©dent", use_container_width=True):
        st.switch_page("pages/4_üìà_Analyse_des_performances.py")

with col3:
    if st.button("Suivant ‚Üí", type="primary", use_container_width=True):
        st.switch_page("pages/6_üéØ_Strat√©gie_marketing.py")

# Style CSS personnalis√©
st.markdown("""
    <style>
    /* Style des onglets */
    .stTabs [data-baseweb="tab-list"] {
        gap: 4px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #f0f2f6;
        border-radius: 4px 4px 0 0;
        gap: 1px;
        padding: 10px 15px;
    }
    
    .stTabs [aria-selected="true"] {
        background-color: #ffffff;
    }
    
    /* Style des expanders */
    .streamlit-expanderHeader {
        font-size: 1.1em;
        font-weight: 600;
    }
    
    /* Style des m√©triques */
    .stMetric {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 10px;
        margin: 5px 0;
    }
    
    .stMetric [data-testid="stMetricLabel"] {
        font-size: 0.9em;
    }
    
    .stMetric [data-testid="stMetricValue"] {
        font-size: 1.3em;
        font-weight: 600;
    }
    
    /* Style des boutons de navigation */
    .stButton>button {
        border-radius: 20px;
        padding: 0.5rem 1rem;
        margin: 10px 0;
    }
    
    /* Style des tableaux */
    .stDataFrame {
        border-radius: 10px;
        overflow: hidden;
    }
    
    /* Style des cartes d'information */
    .info-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 5px solid #4e79a7;
    }
    
    .info-card h4 {
        margin-top: 0;
        color: #2c3e50;
    }
    
    /* Style des graphiques */
    .stPlotlyChart {
        border-radius: 10px;
        border: 1px solid #e1e5ed;
    }
    </style>
""", unsafe_allow_html=True)

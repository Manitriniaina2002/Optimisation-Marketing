import os
import sys
import glob
import logging
import traceback
import zipfile
import io
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, classification_report
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from src.m6_predictive_models import render_sales_objective_prediction_section
try:
    # Import facultatif pour entra√Ænement du mod√®le d'objectif commercial depuis l'UI
    from src.m6_train_objective_model import train_objective_model, EXPECTED_FEATURES, TARGET_NAME
except Exception:
    train_objective_model = None
    EXPECTED_FEATURES = [
        "CA_mensuel",
        "nb_ventes",
        "panier_moyen",
        "taux_conversion",
        "prospects_qualifies",
        "taux_transformation",
    ]
    TARGET_NAME = "objectif_atteint"

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration Streamlit
st.set_page_config(
    page_title="TeeTech Analytics Dashboard", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        text-align: center;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 0.25rem;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 0.25rem;
    }
</style>
""", unsafe_allow_html=True)

class TeeTechAnalytics:
    def __init__(self):
        self.ensure_directories()
        self.targets = {
            'followers_target': 5000,
            'engagement_rate_min': 0.05,
            'ctr_min': 0.02,
            'cpc_max': 50.0,
            'cpa_max': 5000.0,
            'roi_min': 3.0,
            'monthly_revenue_target': 864000.0,
            'conversion_rate_target': 0.04,
            'satisfaction_min': 0.90,
            'nps_min': 50,
            'repeat_rate_min': 0.40
        }

    def ensure_directories(self):
        """Cr√©er les r√©pertoires n√©cessaires"""
        for directory in ['data', 'output', 'reports', 'visualizations']:
            os.makedirs(directory, exist_ok=True)

    def read_csv_robust(self, file_path, sample_size=4096):
        """Lecture robuste de fichiers CSV avec d√©tection automatique"""
        if os.path.getsize(file_path) == 0:
            st.warning(f"Fichier vide: {file_path}")
            return pd.DataFrame()

        encodings = ['utf-8-sig', 'utf-8', 'latin-1', 'cp1252']
        separators = [',', ';', '\t', '|']
        
        for encoding in encodings:
            for sep in separators:
                try:
                    df = pd.read_csv(file_path, encoding=encoding, sep=sep)
                    if len(df.columns) > 1:  # Validation basique
                        return df
                except:
                    continue
        
        # Dernier recours
        try:
            return pd.read_csv(file_path, sep=None, engine='python')
        except Exception as e:
            st.error(f"Impossible de lire le fichier {file_path}: {str(e)}")
            return pd.DataFrame()

    def process_uploaded_files(self, uploaded_files):
        """Traiter les fichiers upload√©s"""
        if not uploaded_files:
            return False
        
        for uploaded_file in uploaded_files:
            file_path = os.path.join('data', uploaded_file.name)
            with open(file_path, 'wb') as f:
                f.write(uploaded_file.read())
            st.success(f"Fichier {uploaded_file.name} upload√© avec succ√®s!")
        
        return True

    def detect_file_type(self, filename):
        """D√©tecter le type de fichier bas√© sur le nom"""
        filename_lower = filename.lower()
        
        if any(word in filename_lower for word in ['customer', 'client']):
            return 'customers'
        elif any(word in filename_lower for word in ['product', 'tshirt', 'tee']):
            return 'products'
        elif any(word in filename_lower for word in ['sale', 'order', 'transaction']):
            return 'sales'
        elif any(word in filename_lower for word in ['marketing', 'campaign', 'ads']):
            return 'marketing'
        else:
            return 'unknown'

    def load_data(self):
        """Charger et d√©tecter automatiquement les fichiers de donn√©es"""
        data_files = glob.glob(os.path.join('data', '*.csv'))
        datasets = {}
        
        for file_path in data_files:
            filename = os.path.basename(file_path)
            file_type = self.detect_file_type(filename)
            
            try:
                df = self.read_csv_robust(file_path)
                if not df.empty:
                    datasets[file_type] = df
                    st.info(f"üìÅ {filename} ‚Üí D√©tect√© comme '{file_type}' ({len(df)} lignes)")
            except Exception as e:
                st.error(f"Erreur lors du chargement de {filename}: {str(e)}")
        
        return datasets

    def clean_and_standardize_data(self, datasets):
        """Nettoyer et standardiser les donn√©es"""
        cleaned_data = {}
        
        # Nettoyage des donn√©es clients
        if 'customers' in datasets:
            df = datasets['customers'].copy()
            df.columns = df.columns.str.lower().str.strip()
            
            # Mapping des colonnes
            column_mapping = {
                'customer_id': ['customer_id', 'id', 'client_id', 'cust_id'],
                'age': ['age', '√¢ge'],
                'city': ['city', 'ville', 'location'],
                'client_type': ['client_type', 'type', 'category', 'segment'],
                'gender': ['gender', 'sex', 'genre'],
                'signup_date': ['signup_date', 'registration_date', 'created_at', 'date_inscription']
            }
            
            standardized = {}
            for target_col, possible_cols in column_mapping.items():
                for col in possible_cols:
                    if col in df.columns:
                        standardized[target_col] = df[col]
                        break
            
            if standardized:
                customers_clean = pd.DataFrame(standardized)
                # Nettoyage des types de donn√©es
                if 'age' in customers_clean.columns:
                    customers_clean['age'] = pd.to_numeric(customers_clean['age'], errors='coerce')
                if 'signup_date' in customers_clean.columns:
                    customers_clean['signup_date'] = pd.to_datetime(customers_clean['signup_date'], errors='coerce')
                # Normalisation du genre
                if 'gender' in customers_clean.columns:
                    def norm_gender(x):
                        if pd.isna(x):
                            return 'U'
                        s = str(x).strip().lower()
                        if s in ['m', 'male', 'homme', 'h']:
                            return 'H'
                        if s in ['f', 'female', 'femme']:
                            return 'F'
                        return 'U'
                    customers_clean['gender'] = customers_clean['gender'].apply(norm_gender)
                
                cleaned_data['customers'] = customers_clean
                customers_clean.to_csv('output/customers_clean.csv', index=False)

        # Nettoyage des donn√©es produits
        if 'products' in datasets:
            df = datasets['products'].copy()
            df.columns = df.columns.str.lower().str.strip()
            
            column_mapping = {
                'product_id': ['product_id', 'id', 'sku', 'code'],
                'name': ['name', 'product_name', 'designation', 'nom'],
                'category': ['category', 'categorie', 'type', 'famille'],
                'price': ['price', 'unit_price', 'prix', 'tarif']
            }
            
            standardized = {}
            for target_col, possible_cols in column_mapping.items():
                for col in possible_cols:
                    if col in df.columns:
                        standardized[target_col] = df[col]
                        break
            
            if standardized:
                products_clean = pd.DataFrame(standardized)
                if 'price' in products_clean.columns:
                    products_clean['price'] = pd.to_numeric(products_clean['price'], errors='coerce')
                
                cleaned_data['products'] = products_clean
                products_clean.to_csv('output/products_clean.csv', index=False)

        # Nettoyage des donn√©es de ventes
        if 'sales' in datasets:
            df = datasets['sales'].copy()
            df.columns = df.columns.str.lower().str.strip()
            
            column_mapping = {
                'order_id': ['order_id', 'id', 'sale_id', 'transaction_id'],
                'customer_id': ['customer_id', 'client_id', 'cust_id'],
                'product_id': ['product_id', 'sku', 'item_id'],
                'order_date': ['order_date', 'date', 'created_at', 'purchase_date'],
                'quantity': ['quantity', 'qty', 'qte'],
                'unit_price': ['unit_price', 'price', 'prix'],
                'total_amount': ['total_amount', 'amount', 'total', 'montant']
            }
            
            standardized = {}
            for target_col, possible_cols in column_mapping.items():
                for col in possible_cols:
                    if col in df.columns:
                        standardized[target_col] = df[col]
                        break
            
            if standardized:
                sales_clean = pd.DataFrame(standardized)
                
                # Nettoyage des types
                if 'order_date' in sales_clean.columns:
                    sales_clean['order_date'] = pd.to_datetime(sales_clean['order_date'], errors='coerce')
                for col in ['quantity', 'unit_price', 'total_amount']:
                    if col in sales_clean.columns:
                        sales_clean[col] = pd.to_numeric(sales_clean[col], errors='coerce')
                
                # Calcul du montant total si manquant
                if 'total_amount' not in sales_clean.columns or sales_clean['total_amount'].isna().all():
                    if 'quantity' in sales_clean.columns and 'unit_price' in sales_clean.columns:
                        sales_clean['total_amount'] = sales_clean['quantity'] * sales_clean['unit_price']
                
                cleaned_data['sales'] = sales_clean
                sales_clean.to_csv('output/sales_clean.csv', index=False)

        # Nettoyage des donn√©es marketing
        if 'marketing' in datasets:
            df = datasets['marketing'].copy()
            df.columns = df.columns.str.lower().str.strip()
            
            column_mapping = {
                'date': ['date', 'day', 'jour'],
                'channel': ['channel', 'canal', 'platform'],
                'campaign': ['campaign', 'campagne', 'campaign_name'],
                'impressions': ['impressions', 'impr', 'vues'],
                'clicks': ['clicks', 'clics'],
                'conversions': ['conversions', 'purchases', 'achats'],
                'cost': ['cost', 'spend', 'cout', 'budget'],
                'revenue': ['revenue', 'revenu', 'ca', 'chiffre_affaires']
            }
            
            standardized = {}
            for target_col, possible_cols in column_mapping.items():
                for col in possible_cols:
                    if col in df.columns:
                        standardized[target_col] = df[col]
                        break
            
            if standardized:
                marketing_clean = pd.DataFrame(standardized)
                
                if 'date' in marketing_clean.columns:
                    marketing_clean['date'] = pd.to_datetime(marketing_clean['date'], errors='coerce')
                
                for col in ['impressions', 'clicks', 'conversions', 'cost', 'revenue']:
                    if col in marketing_clean.columns:
                        marketing_clean[col] = pd.to_numeric(marketing_clean[col], errors='coerce')
                
                # Canal par d√©faut
                if 'channel' not in marketing_clean.columns:
                    marketing_clean['channel'] = 'Facebook'
                
                cleaned_data['marketing'] = marketing_clean
                marketing_clean.to_csv('output/marketing_clean.csv', index=False)

        return cleaned_data

    def perform_customer_segmentation(self, customers_data, sales_data):
        """Segmentation des clients avec RFM"""
        try:
            # Nettoyage et conversion des dates
            if 'order_date' in sales_data.columns:
                sales_data = sales_data.copy()
                sales_data['order_date'] = pd.to_datetime(sales_data['order_date'], errors='coerce')
                # Supprimer les lignes avec des dates invalides
                sales_data = sales_data.dropna(subset=['order_date'])
                
                has_sales = sales_data is not None and not sales_data.empty and 'order_date' in sales_data.columns
                if has_sales:
                    current_date = sales_data['order_date'].max()
                else:
                    current_date = datetime.now()
            else:
                current_date = datetime.now()
                st.warning("Colonne 'order_date' manquante. Utilisation de valeurs par d√©faut pour la r√©cence.")
            
            # Calcul RFM avec gestion des erreurs
            if 'order_date' in sales_data.columns and not sales_data.empty:
                rfm = sales_data.groupby('customer_id').agg({
                    'order_date': lambda x: (current_date - x.max()).days if len(x) > 0 and pd.notna(x.max()) else 365,  # Recency
                    'order_id': 'nunique',  # Frequency  
                    'total_amount': 'sum'   # Monetary
                }).reset_index()
            else:
                # Fallback si pas de dates valides
                rfm = sales_data.groupby('customer_id').agg({
                    'order_id': 'nunique',  # Frequency
                    'total_amount': 'sum'   # Monetary
                }).reset_index()
                rfm['recency'] = 365  # Valeur par d√©faut
            
            rfm.columns = ['customer_id', 'recency', 'frequency', 'monetary']
            
            # Validation des donn√©es RFM
            rfm['recency'] = pd.to_numeric(rfm['recency'], errors='coerce').fillna(365)
            rfm['frequency'] = pd.to_numeric(rfm['frequency'], errors='coerce').fillna(1)
            rfm['monetary'] = pd.to_numeric(rfm['monetary'], errors='coerce').fillna(0)
            
            # Ajout des donn√©es clients si disponibles
            if 'age' in customers_data.columns:
                customer_features = customers_data[['customer_id', 'age']].copy()
                customer_features['age'] = pd.to_numeric(customer_features['age'], errors='coerce').fillna(30)
                rfm = rfm.merge(customer_features, on='customer_id', how='left')
                rfm['age'] = rfm['age'].fillna(30)  # √Çge par d√©faut
            
            # Pr√©paration pour clustering
            feature_cols = ['recency', 'frequency', 'monetary']
            if 'age' in rfm.columns:
                feature_cols.append('age')
            
            X = rfm[feature_cols].copy()
            
            # V√©rification qu'on a des donn√©es valides
            if X.empty or len(X) < 2:
                st.error("Pas assez de donn√©es pour effectuer la segmentation")
                return None, None, None
            
            # Nettoyage final des valeurs aberrantes
            for col in feature_cols:
                # Remplacer les valeurs infinies par NaN puis par la m√©diane
                X[col] = X[col].replace([np.inf, -np.inf], np.nan)
                median_val = X[col].median()
                if pd.isna(median_val):
                    median_val = 0
                X[col] = X[col].fillna(median_val)
            
            # Standardisation
            scaler = StandardScaler()
            try:
                X_scaled = scaler.fit_transform(X)
            except Exception as e:
                st.error(f"Erreur lors de la standardisation: {str(e)}")
                return None, None, None
            
            # Clustering K-means
            optimal_k = self.find_optimal_clusters(X_scaled, max_k=min(8, len(X)))
            
            try:
                kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
                rfm['cluster'] = kmeans.fit_predict(X_scaled)
                
                # Score de silhouette
                if len(np.unique(rfm['cluster'])) > 1:
                    silhouette_avg = silhouette_score(X_scaled, rfm['cluster'])
                else:
                    silhouette_avg = 0
                    
            except Exception as e:
                st.error(f"Erreur lors du clustering: {str(e)}")
                # Fallback: segmentation simple bas√©e sur la valeur mon√©taire
                rfm['cluster'] = pd.cut(rfm['monetary'], bins=3, labels=[0,1,2]).astype(int)
                silhouette_avg = 0
                optimal_k = 3
                st.warning("Utilisation d'une segmentation simplifi√©e bas√©e sur la valeur mon√©taire.")
            
            # Sauvegarde
            rfm.to_csv('output/customer_segments.csv', index=False)
            
            return rfm, silhouette_avg, optimal_k
            
        except Exception as e:
            st.error(f"Erreur lors de la segmentation: {str(e)}")
            # Informations de debug
            if 'sales_data' in locals():
                st.write("**Colonnes dans sales_data:**", list(sales_data.columns))
                if 'order_date' in sales_data.columns:
                    st.write("**Types de donn√©es dans order_date:**", sales_data['order_date'].dtype)
                    st.write("**Exemples de order_date:**", sales_data['order_date'].head().tolist())
            return None, None, None

    def find_optimal_clusters(self, X, max_k=8):
        """Trouver le nombre optimal de clusters"""
        try:
            n_samples = len(X)
            if n_samples < 4:
                return 2
            
            # Limiter max_k selon le nombre d'√©chantillons
            max_k = min(max_k, n_samples - 1, 8)
            
            if max_k < 2:
                return 2
            
            silhouette_scores = []
            K_range = range(2, max_k + 1)
            
            for k in K_range:
                try:
                    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                    labels = kmeans.fit_predict(X)
                    
                    # V√©rifier qu'il y a au moins 2 clusters diff√©rents
                    if len(np.unique(labels)) > 1:
                        score = silhouette_score(X, labels)
                        silhouette_scores.append(score)
                    else:
                        silhouette_scores.append(-1)  # Score faible si un seul cluster
                        
                except Exception as e:
                    st.warning(f"Erreur pour k={k}: {str(e)}")
                    silhouette_scores.append(-1)
            
            if not silhouette_scores or all(score <= 0 for score in silhouette_scores):
                return 3  # Valeur par d√©faut
            
            best_k_index = silhouette_scores.index(max(silhouette_scores))
            optimal_k = K_range[best_k_index]
            return optimal_k
            
        except Exception as e:
            st.warning(f"Erreur dans find_optimal_clusters: {str(e)}")
            return 3  # Valeur par d√©faut s√ªre

    def create_customer_personas(self, segments_data, customers_data, sales_data, products_data):
        """Cr√©er des personas d√©taill√©s"""
        try:
            # Fonction helper pour obtenir le mode en s√©curit√©
            def safe_mode(series, fallback='Unknown'):
                try:
                    if series.empty or series.isna().all():
                        return fallback
                    mode_values = series.mode(dropna=True)
                    return mode_values.iloc[0] if len(mode_values) > 0 else fallback
                except Exception:
                    return fallback
            
            # Pr√©paration des donn√©es de ventes enrichies
            sales_enriched = sales_data.copy()
            
            # Enrichissement avec donn√©es produits si disponibles et compatibles
            if (not products_data.empty and 
                'product_id' in products_data.columns and 
                'product_id' in sales_data.columns):
                
                try:
                    # Assurer la compatibilit√© des types pour le merge
                    products_clean = products_data.copy()
                    products_clean['product_id'] = products_clean['product_id'].astype(str)
                    sales_enriched['product_id'] = sales_enriched['product_id'].astype(str)
                    
                    # S√©lectionner seulement les colonnes n√©cessaires
                    merge_cols = ['product_id']
                    if 'category' in products_clean.columns:
                        merge_cols.append('category')
                    elif 'name' in products_clean.columns:
                        # Utiliser le nom comme proxy de cat√©gorie
                        products_clean['category'] = products_clean['name']
                        merge_cols.append('category')
                    
                    if len(merge_cols) > 1:
                        sales_enriched = sales_enriched.merge(
                            products_clean[merge_cols], 
                            on='product_id', 
                            how='left'
                        )
                        st.info(f"‚úÖ Donn√©es produits int√©gr√©es: {len(products_clean)} produits")
                    else:
                        sales_enriched['category'] = 'Unknown'
                        st.warning("‚ö†Ô∏è Pas de cat√©gorie trouv√©e dans les donn√©es produits")
                        
                except Exception as e:
                    sales_enriched['category'] = 'Unknown'
                    st.warning(f"‚ö†Ô∏è Impossible d'int√©grer les donn√©es produits: {str(e)}")
            else:
                sales_enriched['category'] = 'Unknown'
                if products_data.empty:
                    st.info("‚ÑπÔ∏è Pas de donn√©es produits disponibles")
            
            personas = {}
            
            # V√©rification des colonnes essentielles
            if 'cluster' not in segments_data.columns:
                st.error("‚ùå Colonne 'cluster' manquante dans les donn√©es de segmentation")
                return {}
            
            if 'customer_id' not in segments_data.columns:
                st.error("‚ùå Colonne 'customer_id' manquante dans les donn√©es de segmentation")
                return {}
                
            # Cr√©ation des personas pour chaque cluster
            for cluster_id in sorted(segments_data['cluster'].unique()):
                try:
                    cluster_customers = segments_data[segments_data['cluster'] == cluster_id]['customer_id']
                    
                    if len(cluster_customers) == 0:
                        continue
                    
                    # Statistiques RFM du cluster
                    cluster_rfm = segments_data[segments_data['cluster'] == cluster_id]
                    
                    # Statistiques d√©mographiques
                    cluster_demo = customers_data[customers_data['customer_id'].isin(cluster_customers)]
                    
                    # Comportement d'achat
                    cluster_sales = sales_enriched[sales_enriched['customer_id'].isin(cluster_customers)]
                    
                    # Cat√©gories pr√©f√©r√©es
                    top_categories = {}
                    if not cluster_sales.empty and 'category' in cluster_sales.columns:
                        category_counts = cluster_sales['category'].value_counts().head(5)
                        top_categories = category_counts.to_dict()
                    
                    # Calcul des m√©triques avec gestion des erreurs
                    def safe_mean(series, default=0):
                        try:
                            return series.mean() if not series.empty and not series.isna().all() else default
                        except:
                            return default
                    
                    def safe_sum(series, default=0):
                        try:
                            return series.sum() if not series.empty and not series.isna().all() else default
                        except:
                            return default
                    
                    # Construction du persona
                    persona = {
                        'size': len(cluster_customers),
                        'avg_recency': safe_mean(cluster_rfm['recency']) if 'recency' in cluster_rfm.columns else 0,
                        'avg_frequency': safe_mean(cluster_rfm['frequency']) if 'frequency' in cluster_rfm.columns else 0,
                        'avg_monetary': safe_mean(cluster_rfm['monetary']) if 'monetary' in cluster_rfm.columns else 0,
                        'avg_age': safe_mean(cluster_demo['age']) if 'age' in cluster_demo.columns else None,
                        'top_city': safe_mode(cluster_demo['city']) if 'city' in cluster_demo.columns else 'Unknown',
                        'top_categories': top_categories,
                        'total_revenue': safe_sum(cluster_sales['total_amount']) if 'total_amount' in cluster_sales.columns else 0,
                        'avg_order_value': safe_mean(cluster_sales['total_amount']) if 'total_amount' in cluster_sales.columns else 0,
                        'order_count': len(cluster_sales) if not cluster_sales.empty else 0
                    }
                    
                    personas[f"Segment_{cluster_id}"] = persona
                    
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erreur lors de la cr√©ation du persona pour le cluster {cluster_id}: {str(e)}")
                    continue
            
            if not personas:
                st.error("‚ùå Aucun persona n'a pu √™tre cr√©√©")
                return {}
                
            st.success(f"‚úÖ {len(personas)} personas cr√©√©s avec succ√®s!")
            return personas
            
        except Exception as e:
            st.error(f"‚ùå Erreur g√©n√©rale lors de la cr√©ation des personas: {str(e)}")
            # Debug info
            if 'segments_data' in locals():
                st.write("**Colonnes dans segments_data:**", list(segments_data.columns))
            if 'sales_data' in locals():
                st.write("**Colonnes dans sales_data:**", list(sales_data.columns))
            if 'products_data' in locals() and not products_data.empty:
                st.write("**Colonnes dans products_data:**", list(products_data.columns))
            return {}

    def calculate_marketing_kpis(self, marketing_data):
        """Calculer les KPIs marketing"""
        try:
            df = marketing_data.copy()
            # Assurer des types num√©riques pour les colonnes cl√©s
            num_cols = ['impressions', 'clicks', 'conversions', 'cost', 'revenue']
            for c in num_cols:
                if c in df.columns:
                    df[c] = pd.to_numeric(df[c], errors='coerce')
            # Remplacer NaN par 0 pour √©viter les erreurs dans les agr√©gations
            for c in num_cols:
                if c in df.columns:
                    df[c] = df[c].fillna(0)
            
            # KPIs de base
            df['ctr'] = df['clicks'] / df['impressions'].replace(0, np.nan)
            df['cvr'] = df['conversions'] / df['clicks'].replace(0, np.nan)
            df['cpc'] = df['cost'] / df['clicks'].replace(0, np.nan)
            df['cpa'] = df['cost'] / df['conversions'].replace(0, np.nan)
            
            if 'revenue' in df.columns:
                df['roas'] = df['revenue'] / df['cost'].replace(0, np.nan)
                df['roi'] = (df['revenue'] - df['cost']) / df['cost'].replace(0, np.nan)
            
            # Agr√©gation globale
            summary = {
                'total_impressions': float(df['impressions'].sum()) if 'impressions' in df.columns else 0.0,
                'total_clicks': float(df['clicks'].sum()) if 'clicks' in df.columns else 0.0,
                'total_conversions': float(df['conversions'].sum()) if 'conversions' in df.columns else 0.0,
                'total_cost': float(df['cost'].sum()) if 'cost' in df.columns else 0.0,
                'total_revenue': float(df['revenue'].sum()) if 'revenue' in df.columns else 0.0,
            }
            
            # KPIs globaux
            summary['overall_ctr'] = summary['total_clicks'] / summary['total_impressions'] if summary['total_impressions'] > 0 else 0
            summary['overall_cvr'] = summary['total_conversions'] / summary['total_clicks'] if summary['total_clicks'] > 0 else 0
            summary['overall_cpc'] = summary['total_cost'] / summary['total_clicks'] if summary['total_clicks'] > 0 else 0
            summary['overall_cpa'] = summary['total_cost'] / summary['total_conversions'] if summary['total_conversions'] > 0 else 0
            summary['overall_roas'] = summary['total_revenue'] / summary['total_cost'] if summary['total_cost'] > 0 else 0
            
            # Benchmark vs objectifs
            benchmarks = []
            for kpi, value in [
                ('CTR', summary['overall_ctr']),
                ('CPC', summary['overall_cpc']),
                ('CPA', summary['overall_cpa']),
                ('ROAS', summary['overall_roas'])
            ]:
                target_key = f"{kpi.lower()}_{'min' if kpi in ['CTR', 'ROAS'] else 'max'}"
                target = self.targets.get(target_key, 0)
                
                # Forcer la comparaison sur des floats robustes
                try:
                    v = float(value) if value is not None else 0.0
                except Exception:
                    v = 0.0
                try:
                    t = float(target) if target is not None else 0.0
                except Exception:
                    t = 0.0

                if kpi in ['CTR', 'ROAS']:
                    status = 'Atteint' if v >= t else '√Ä am√©liorer'
                else:
                    status = 'Atteint' if v <= t else '√Ä am√©liorer'
                
                benchmarks.append({
                    'KPI': kpi,
                    'Valeur': v,
                    'Objectif': t,
                    'Statut': status
                })
            
            df.to_csv('output/campaign_kpis.csv', index=False)
            pd.DataFrame(benchmarks).to_csv('output/kpi_benchmark.csv', index=False)
            
            return df, summary, benchmarks
            
        except Exception as e:
            st.error(f"Erreur lors du calcul des KPIs: {str(e)}")
            return None, None, None

    def build_predictive_model(self, customers_data, sales_data):
        """Construire un mod√®le pr√©dictif de churn"""
        try:
            # Pr√©paration des donn√©es pour pr√©diction churn
            if 'order_date' in sales_data.columns:
                sales_data_clean = sales_data.copy()
                sales_data_clean['order_date'] = pd.to_datetime(sales_data_clean['order_date'], errors='coerce')
                sales_data_clean = sales_data_clean.dropna(subset=['order_date'])
                
                if not sales_data_clean.empty:
                    current_date = sales_data_clean['order_date'].max()
                else:
                    current_date = datetime.now()
                    sales_data_clean = sales_data.copy()
            else:
                current_date = datetime.now()
                sales_data_clean = sales_data.copy()
                st.warning("‚ö†Ô∏è Pas de colonne de dates. Utilisation de valeurs par d√©faut.")
            
            # V√©rification des colonnes essentielles
            required_cols = ['customer_id', 'total_amount']
            missing_cols = [col for col in required_cols if col not in sales_data_clean.columns]
            
            if missing_cols:
                st.error(f"‚ùå Colonnes manquantes pour le mod√®le pr√©dictif: {missing_cols}")
                return None, None, None
            
            # Calcul des features avec gestion robuste
            try:
                # Cr√©ation de la colonne order_id si manquante
                if 'order_id' not in sales_data_clean.columns:
                    sales_data_clean['order_id'] = range(len(sales_data_clean))

                # Named aggregation pour √©viter les colonnes multi-index
                agg_kwargs = {
                    'total_spent': ('total_amount', 'sum'),
                    'avg_order_value': ('total_amount', 'mean'),
                    'orders_count': ('total_amount', 'count'),
                }
                if 'order_id' in sales_data_clean.columns:
                    agg_kwargs['order_id_nunique'] = ('order_id', 'nunique')
                if 'order_date' in sales_data_clean.columns:
                    agg_kwargs['recency'] = (
                        'order_date',
                        lambda x: (current_date - x.max()).days if len(x) > 0 and pd.notna(x.max()) else 365,
                    )

                customer_features = (
                    sales_data_clean
                    .groupby('customer_id')
                    .agg(**agg_kwargs)
                    .reset_index()
                )

                # D√©duire frequency depuis orders_count ou order_id_nunique
                if 'order_id_nunique' in customer_features.columns:
                    customer_features['frequency'] = customer_features['order_id_nunique']
                else:
                    customer_features['frequency'] = customer_features['orders_count']

                # Valeurs par d√©faut si certains champs manquent
                if 'recency' not in customer_features.columns:
                    customer_features['recency'] = 365
                for c in ['total_spent', 'avg_order_value', 'frequency']:
                    if c not in customer_features.columns:
                        customer_features[c] = 0

            except Exception as e:
                st.error(f"‚ùå Erreur lors de l'agr√©gation des donn√©es: {str(e)}")
                st.write({'agg_input_cols': list(sales_data_clean.columns)})
                return None, None, None
            
            # Merge avec donn√©es clients si disponibles
            if any(col in customers_data.columns for col in ['age', 'gender', 'city']):
                try:
                    demo_cols = ['customer_id']
                    if 'age' in customers_data.columns:
                        demo_cols.append('age')
                    if 'gender' in customers_data.columns:
                        demo_cols.append('gender')
                    if 'city' in customers_data.columns:
                        demo_cols.append('city')
                    customer_demo = customers_data[demo_cols].copy()
                    if 'age' in customer_demo.columns:
                        customer_demo['age'] = pd.to_numeric(customer_demo['age'], errors='coerce').fillna(30)
                    # Fusion
                    customer_features = customer_features.merge(customer_demo, on='customer_id', how='left')
                    if 'age' in customer_features.columns:
                        customer_features['age'] = customer_features['age'].fillna(30)
                    # Encodage one-hot du genre (H/F/U)
                    if 'gender' in customer_features.columns:
                        customer_features['gender'] = customer_features['gender'].fillna('U')
                        gender_dummies = pd.get_dummies(customer_features['gender'], prefix='gender')
                        # Conserver H et F, U optionnel
                        for col in ['gender_H', 'gender_F']:
                            if col not in gender_dummies.columns:
                                gender_dummies[col] = 0
                        customer_features = pd.concat([customer_features, gender_dummies[['gender_H', 'gender_F']]], axis=1)
                    # Encodage one-hot des villes (top 10)
                    if 'city' in customer_features.columns:
                        # D√©terminer top villes sur l'ensemble clients dispo
                        try:
                            top_cities = (
                                customers_data['city'].dropna().astype(str).str.strip().value_counts().head(10).index.tolist()
                            )
                        except Exception:
                            top_cities = []
                        customer_features['city'] = customer_features['city'].astype(str).str.strip().fillna('Autres')
                        customer_features['city_encoded'] = customer_features['city'].where(customer_features['city'].isin(top_cities), 'Autres')
                        city_dummies = pd.get_dummies(customer_features['city_encoded'], prefix='city')
                        # S'assurer que colonnes existent m√™me si absentes
                        ensure_cols = [f'city_{c}' for c in top_cities] + ['city_Autres']
                        for col in ensure_cols:
                            if col not in city_dummies.columns:
                                city_dummies[col] = 0
                        customer_features = pd.concat([customer_features, city_dummies[ensure_cols]], axis=1)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Impossible d'int√©grer les donn√©es d√©mographiques: {str(e)}")
            
            # D√©finition du churn (pas d'achat depuis X jours)
            churn_threshold = 90  # jours
            customer_features['is_churned'] = (customer_features['recency'] > churn_threshold).astype(int)
            
            # Pr√©paration des features pour le mod√®le
            feature_columns = ['recency', 'frequency', 'total_spent', 'avg_order_value']
            if 'age' in customer_features.columns:
                feature_columns.append('age')
            if 'gender_H' in customer_features.columns:
                feature_columns.append('gender_H')
            if 'gender_F' in customer_features.columns:
                feature_columns.append('gender_F')
            # Ajouter villes encod√©es (limiter √† 11 colonnes max: top10 + autres)
            city_cols = [c for c in customer_features.columns if c.startswith('city_')]
            # Garder au plus 11 colonnes pour √©viter haute dimension
            if city_cols:
                feature_columns.extend(city_cols[:11])

            # Validation et nettoyage des features
            X = customer_features[feature_columns].copy()

            # S'assurer que les colonnes existent et sont bien form√©es
            missing_feats = [c for c in feature_columns if c not in X.columns]
            if missing_feats:
                st.error(f"‚ùå Colonnes de features manquantes: {missing_feats}")
                return None, None, None

            for col in feature_columns:
                X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)
                # Remplacer les valeurs infinies
                median_val = X[col].replace([np.inf, -np.inf], np.nan).median()
                if pd.isna(median_val):
                    median_val = 0
                X[col] = X[col].replace([np.inf, -np.inf], median_val).fillna(median_val)

            # y en Series 1-D
            y = pd.Series(customer_features['is_churned']).astype(int)
            
            # V√©rification qu'on a assez de donn√©es
            if len(X) < 10:
                st.warning("‚ö†Ô∏è Pas assez de donn√©es pour un mod√®le robuste (minimum 10 clients)")
                return None, None, None
            
            # V√©rification qu'on a des cas de churn et de non-churn
            if len(y.unique()) < 2:
                st.warning("‚ö†Ô∏è Tous les clients ont le m√™me statut de churn. Ajustement du seuil.")
                # Ajuster le seuil de churn
                churn_threshold = customer_features['recency'].median()
                customer_features['is_churned'] = (customer_features['recency'] > churn_threshold).astype(int)
                # Assurer que y reste une Series 1-D apr√®s r√©ajustement
                y = pd.Series(customer_features['is_churned']).astype(int)
                
                if len(y.unique()) < 2:
                    st.error("‚ùå Impossible de cr√©er un mod√®le de churn avec ces donn√©es")
                    return None, None, None
            
            # Division train/test
            # Coercition finale des types
            X = X.astype(float)
            y = pd.Series(y).astype(int)

            try:
                test_size = 0.2 if len(X) >= 20 else 0.3
                # Stratification conditionnelle selon la disponibilit√© des classes
                class_counts = y.value_counts()
                can_stratify = (class_counts.min() >= 2) and (len(class_counts) >= 2)
                stratify_arg = y if can_stratify else None
                if not can_stratify:
                    st.info("‚ÑπÔ∏è Stratification d√©sactiv√©e (classes insuffisantes). Split al√©atoire simple utilis√©.")
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=42, stratify=stratify_arg
                )
                # Coercition apr√®s split
                X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)
                X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)
                y_train = pd.Series(y_train).astype(int)
                y_test = pd.Series(y_test).astype(int)
                # Aplatir pour sklearn si n√©cessaire
                y_train = y_train.to_numpy().ravel()
                y_test = y_test.to_numpy().ravel()
            except Exception as e:
                st.error(f"‚ùå Erreur lors du split train/test: {str(e)}")
                st.write({
                    'X_shape': X.shape,
                    'y_len': len(y),
                    'y_unique': y.unique().tolist() if hasattr(y, 'unique') else None
                })
                return None, None, None
            
            # Entra√Ænement du mod√®le
            model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)
            try:
                model.fit(X_train, y_train)
            except Exception as e:
                st.error(f"‚ùå Erreur lors de l'entra√Ænement du mod√®le: {str(e)}")
                st.write({
                    'X_train_shape': X_train.shape,
                    'y_train_type': type(y_train).__name__,
                    'y_train_shape': getattr(y_train, 'shape', None),
                    'y_train_preview': y_train[:10].tolist() if hasattr(y_train, 'tolist') else None
                })
                return None, None, None
            
            # Pr√©dictions et m√©triques
            try:
                y_pred_proba = model.predict_proba(X_test)[:, 1]
                auc_score = roc_auc_score(y_test, y_pred_proba)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Impossible de calculer l'AUC: {str(e)}")
                st.write({'y_test_type': type(y_test).__name__, 'y_test_head': getattr(y_test, 'head', lambda: y_test)()})
                auc_score = 0
            
            # Feature importance
            feature_importance = pd.DataFrame({
                'feature': feature_columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            # Pr√©dictions sur tous les clients
            try:
                all_predictions = model.predict_proba(X)[:, 1]
                customer_features['churn_probability'] = all_predictions
                
                # D√©finition des niveaux de risque
                customer_features['churn_risk'] = pd.cut(
                    customer_features['churn_probability'],
                    bins=[0, 0.3, 0.7, 1.0],
                    labels=['Faible', 'Moyen', '√âlev√©'],
                    include_lowest=True
                )
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors des pr√©dictions: {str(e)}")
                return None, None, None
            
            # Sauvegarde
            try:
                customer_features.to_csv('output/churn_predictions.csv', index=False)
                feature_importance.to_csv('output/feature_importance.csv', index=False)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur lors de la sauvegarde: {str(e)}")
            
            return customer_features, feature_importance, auc_score
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la construction du mod√®le pr√©dictif: {str(e)}")
            # Debug info
            if 'sales_data' in locals():
                st.write("**Colonnes dans sales_data:**", list(sales_data.columns))
            if 'customers_data' in locals():
                st.write("**Colonnes dans customers_data:**", list(customers_data.columns))
            return None, None, None

    def create_visualizations(self, customers_data, sales_data, marketing_data, segments_data, personas):
        """Cr√©er toutes les visualisations"""
        viz_results = {}
        
        # 1. Distribution des segments
        if segments_data is not None and not segments_data.empty:
            fig_segments = px.pie(
                values=segments_data['cluster'].value_counts().values,
                names=[f'Segment {i}' for i in segments_data['cluster'].value_counts().index],
                title='Distribution des Segments Clients'
            )
            viz_results['segments_distribution'] = fig_segments
        
        # 2. RFM Analysis
        if segments_data is not None and not segments_data.empty:
            fig_rfm = make_subplots(
                rows=2, cols=2,
                subplot_titles=('R√©cence', 'Fr√©quence', 'Valeur Mon√©taire', 'RFM par Segment')
            )
            
            for i, col in enumerate(['recency', 'frequency', 'monetary']):
                if col in segments_data.columns:
                    fig_rfm.add_trace(
                        go.Histogram(x=segments_data[col], name=col.title()),
                        row=(i//2)+1, col=(i%2)+1
                    )
            
            # Scatter RFM par segment
            if all(col in segments_data.columns for col in ['frequency', 'monetary', 'cluster']):
                fig_rfm.add_trace(
                    go.Scatter(
                        x=segments_data['frequency'],
                        y=segments_data['monetary'],
                        mode='markers',
                        color=segments_data['cluster'],
                        name='Segments'
                    ),
                    row=2, col=2
                )
            
            fig_rfm.update_layout(height=600, title_text="Analyse RFM")
            viz_results['rfm_analysis'] = fig_rfm
        
        # 3. √âvolution des ventes
        has_sales = sales_data is not None and not sales_data.empty and 'order_date' in sales_data.columns
        if has_sales:
            sales_timeline = sales_data.groupby(sales_data['order_date'].dt.date)['total_amount'].sum().reset_index()
            
            fig_timeline = px.line(
                sales_timeline,
                x='order_date',
                y='total_amount',
                title='√âvolution du Chiffre d\'Affaires'
            )
            viz_results['sales_timeline'] = fig_timeline
        
        # 4. Performance Marketing
        if not marketing_data.empty:
            # KPIs par canal
            if 'channel' in marketing_data.columns:
                channel_performance = marketing_data.groupby('channel').agg({
                    'impressions': 'sum',
                    'clicks': 'sum',
                    'cost': 'sum',
                    'conversions': 'sum' if 'conversions' in marketing_data.columns else lambda x: 0
                }).reset_index()
                
                channel_performance['ctr'] = channel_performance['clicks'] / channel_performance['impressions']
                channel_performance['cpc'] = channel_performance['cost'] / channel_performance['clicks']
                
                fig_channels = px.bar(
                    channel_performance,
                    x='channel',
                    y=['impressions', 'clicks', 'conversions'],
                    title='Performance par Canal Marketing'
                )
                viz_results['channel_performance'] = fig_channels
        
        # 5. Personas Comparison
        if personas:
            personas_df = pd.DataFrame.from_dict(personas, orient='index').reset_index()
            personas_df.columns = ['Segment'] + list(personas_df.columns[1:])
            
            fig_personas = px.bar(
                personas_df,
                x='Segment',
                y='avg_monetary',
                title='Valeur Moyenne par Segment',
                color='avg_frequency'
            )
            viz_results['personas_comparison'] = fig_personas
        
        return viz_results

    def generate_comprehensive_report(self, customers_data, sales_data, marketing_data, 
                                    segments_data, personas, kpi_summary, churn_data):
        """G√©n√©rer un rapport complet"""
        # Utiliser les ventes trait√©es si disponibles, sinon reconstruire
        sd = (st.session_state.get('sales_processed') if 'sales_processed' in st.session_state else sales_data).copy()
        default_unit_price = float(st.session_state.get('default_unit_price', 0.0))
        # Reconstruire total_amount si manquant/NaN/0
        if not sd.empty:
            unit_cols = [c for c in sd.columns if c in ['unit_price', 'price', 'prix']]
            qty_cols = [c for c in sd.columns if c in ['quantity', 'qty', 'quantite', 'quantit√©']]
            qt = pd.Series(0, index=sd.index)
            if qty_cols:
                qt = pd.to_numeric(sd[qty_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(0)
            if unit_cols:
                up = pd.to_numeric(sd[unit_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(default_unit_price)
            else:
                up = pd.Series(default_unit_price, index=sd.index)
            if 'total_amount' not in sd.columns:
                sd['total_amount'] = (up * qt)
            else:
                ta_clean = pd.to_numeric(sd['total_amount'].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce')
                sd['total_amount'] = ta_clean.where(ta_clean.notna() & (ta_clean > 0), (up * qt))
        # S√©curisation des types
        if 'order_date' in sd.columns:
            sd['order_date'] = pd.to_datetime(sd['order_date'], errors='coerce')
        if 'total_amount' in sd.columns:
            sd['total_amount'] = pd.to_numeric(sd['total_amount'], errors='coerce')
        # Valeurs s√ªres
        total_ca = float(sd['total_amount'].sum()) if 'total_amount' in sd.columns else 0.0
        avg_basket = float(sd['total_amount'].mean()) if 'total_amount' in sd.columns else 0.0
        order_count = int(sd['order_id'].nunique()) if 'order_id' in sd.columns else len(sd)
        active_customers = int(sd['customer_id'].nunique()) if 'customer_id' in sd.columns else 0
        period_min = sd['order_date'].min() if 'order_date' in sd.columns else None
        period_max = sd['order_date'].max() if 'order_date' in sd.columns else None
        # kpi_summary s√©curis√©
        ks = kpi_summary or {}
        def fget(d, k, default=0.0):
            try:
                return float(d.get(k, default))
            except Exception:
                return default
        ks_total_impr = fget(ks, 'total_impressions')
        ks_total_clicks = fget(ks, 'total_clicks')
        ks_total_conv = fget(ks, 'total_conversions')
        ks_total_cost = fget(ks, 'total_cost')
        ks_total_rev = fget(ks, 'total_revenue')
        ks_ctr = fget(ks, 'overall_ctr')
        ks_cvr = fget(ks, 'overall_cvr')
        ks_cpc = fget(ks, 'overall_cpc')
        ks_cpa = fget(ks, 'overall_cpa')
        ks_roas = fget(ks, 'overall_roas')
        report_content = f"""
# RAPPORT D'ANALYSE MARKETING - TEETECH DESIGN
**G√©n√©r√© le : {datetime.now().strftime('%d/%m/%Y √† %H:%M')}**

## R√âSUM√â EX√âCUTIF

### Donn√©es Analys√©es
- **Clients** : {len(customers_data)} enregistrements
- **Ventes** : {len(sd)} transactions
- **Campagnes Marketing** : {len(marketing_data)} entr√©es
- **P√©riode d'analyse** : {period_min.strftime('%d/%m/%Y') if period_min is not None and pd.notna(period_min) else 'Non disponible'} - {period_max.strftime('%d/%m/%Y') if period_max is not None and pd.notna(period_max) else 'Non disponible'}

### Indicateurs Cl√©s
- **Chiffre d'Affaires Total** : {total_ca:,.0f} Ar
- **Panier Moyen** : {avg_basket:,.0f} Ar
- **Nombre de Commandes** : {order_count}
- **Clients Actifs** : {active_customers if active_customers>0 else 'N/A'}

## ANALYSE DE SEGMENTATION

### Vue d'ensemble
{f"Nombre de segments identifi√©s : {segments_data['cluster'].nunique()}" if segments_data is not None else "Segmentation non disponible"}

### Profils des Segments"""

        # Ajout des personas
        if personas:
            for segment_name, persona_data in personas.items():
                report_content += f"""

#### {segment_name.replace('_', ' ').title()}
- **Taille** : {persona_data['size']} clients ({persona_data['size']/len(customers_data)*100:.1f}% de la base)
- **R√©cence moyenne** : {persona_data['avg_recency']:.0f} jours
- **Fr√©quence d'achat** : {persona_data['avg_frequency']:.1f} commandes
- **Valeur moyenne** : {persona_data['avg_monetary']:,.0f} Ar
- **√Çge moyen** : {persona_data['avg_age']:.0f} ans (si disponible)
- **Ville principale** : {persona_data['top_city']}
- **Cat√©gories pr√©f√©r√©es** : {', '.join(list(persona_data['top_categories'].keys())[:3])}
- **Revenus g√©n√©r√©s** : {persona_data['total_revenue']:,.0f} Ar"""

        # Performance Marketing
        if kpi_summary:
            report_content += f"""

## PERFORMANCE MARKETING

### KPIs Globaux
- **Impressions totales** : {ks_total_impr:,.0f}
- **Clics totaux** : {ks_total_clicks:,.0f}
- **Conversions** : {ks_total_conv:,.0f}
- **Co√ªt total** : {ks_total_cost:,.0f} Ar
- **Revenus** : {ks_total_rev:,.0f} Ar

### Ratios de Performance
- **CTR** : {ks_ctr*100:.2f}%
- **CVR** : {ks_cvr*100:.2f}%
- **CPC** : {ks_cpc:,.0f} Ar
- **CPA** : {ks_cpa:,.0f} Ar
- **ROAS** : {ks_roas:.2f}x"""

        # Analyse Pr√©dictive
        if churn_data is not None:
            churn_stats = churn_data['churn_risk'].value_counts()
            report_content += f"""

## ANALYSE PR√âDICTIVE - RISQUE DE CHURN

### Distribution du Risque
- **Risque Faible** : {churn_stats.get('Faible', 0)} clients
- **Risque Moyen** : {churn_stats.get('Moyen', 0)} clients  
- **Risque √âlev√©** : {churn_stats.get('√âlev√©', 0)} clients

### Recommandations par Niveau de Risque
#### Clients √† Risque √âlev√© ({churn_stats.get('√âlev√©', 0)} clients)
- Campagnes de r√©tention imm√©diates
- Offres personnalis√©es exclusives
- Contact direct par l'√©quipe commerciale

#### Clients √† Risque Moyen ({churn_stats.get('Moyen', 0)} clients)
- Programmes de fid√©lisation
- Communications cibl√©es
- Offres incitatives

#### Clients √† Faible Risque ({churn_stats.get('Faible', 0)} clients)
- Maintenir l'engagement
- Programmes d'ambassadeurs
- Cross-selling/Up-selling"""

        report_content += """

## RECOMMANDATIONS STRAT√âGIQUES

### Court Terme (1-3 mois)
1. **üìà R√©tention Clients** : Lancer des campagnes cibl√©es pour les clients √† risque √©lev√©
2. **üìà Optimisation Marketing** : R√©allouer le budget vers les canaux les plus performants
3. **üìà Personnalisation** : Adapter les offres par segment client

### Moyen Terme (3-6 mois)
1. **üìà D√©veloppement Produits** : Cr√©er des produits adapt√©s aux segments les plus rentables
2. **üìà Acquisition** : Cibler des prospects similaires aux clients √† forte valeur
3. **üìà Automatisation** : Mettre en place des workflows marketing automatis√©s

### Long Terme (6-12 mois)
1. **üìà Expansion** : Explorer de nouveaux march√©s bas√©s sur l'analyse des segments
2. **üìà Innovation** : D√©velopper de nouvelles cat√©gories de produits
3. **üìà Fid√©lisation** : Cr√©er un programme de fid√©lit√© complet

## CONCLUSION

Cette analyse r√©v√®le des opportunit√©s significatives d'optimisation de la strat√©gie marketing de TeeTech Design. 
La segmentation client√®le permet une approche plus cibl√©e, tandis que l'analyse pr√©dictive aide √† pr√©venir le churn.

Les recommandations propos√©es, si mises en ≈ìuvre, devraient permettre d'atteindre les objectifs fix√©s :
- Augmentation du chiffre d'affaires de 20%
- Am√©lioration du taux de conversion √† 4%
- R√©duction du co√ªt d'acquisition client

---
*Rapport g√©n√©r√© automatiquement par le syst√®me d'analyse TeeTech*
"""
        
        # Sauvegarde du rapport
        with open('reports/rapport_complet.md', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return report_content

def main():
    # En-t√™te
    st.markdown('<h1 class="main-header">üéØ TeeTech Analytics Dashboard</h1>', unsafe_allow_html=True)
    st.markdown("---")
    
    # Initialisation
    analytics = TeeTechAnalytics()
    
    # Sidebar pour navigation
    with st.sidebar:
        st.header("üìã Menu Principal")
        
        selected_tab = st.selectbox(
            "S√©lectionner un module",
            ["üè† Accueil", "üì§ Import de Donn√©es", "üßπ M2: Nettoyage", 
             "üë• M3: Segmentation", "üé≠ M4: Personas", "üìä M5: Marketing KPIs", 
             "üîÆ M6: Analyse Pr√©dictive", "üìà Dashboard Complet", "üìë Rapport Final"]
        )
        
        st.markdown("---")
        st.info("üí° **Tip**: Commencez par importer vos donn√©es, puis suivez les modules dans l'ordre.")

    # Module Accueil
    if selected_tab == "üè† Accueil":
        st.header("Bienvenue dans TeeTech Analytics")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä Modules", "8", "Complets")
        with col2:
            st.metric("üéØ KPIs", "15+", "Suivis")
        with col3:
            st.metric("üìà Visualisations", "20+", "Graphiques")
        
        st.markdown("""
        ### üöÄ Guide de D√©marrage Rapide
        
        1. **üì§ Import de Donn√©es** : Uploadez vos fichiers CSV
        2. **üßπ M2: Nettoyage** : Standardisation automatique des donn√©es
        3. **üë• M3: Segmentation** : Classification RFM des clients
        4. **üé≠ M4: Personas** : Profils d√©taill√©s par segment
        5. **üìä M5: Marketing KPIs** : Performance des campagnes
        6. **üîÆ M6: Analyse Pr√©dictive** : Mod√®le de pr√©diction de churn
        7. **üìà Dashboard Complet** : Vue d'ensemble interactive
        8. **üìë Rapport Final** : Synth√®se compl√®te exportable
        """)
        
        # √âtat des fichiers
        st.subheader("üìÇ √âtat des Fichiers")
        data_files = glob.glob('data/*.csv')
        output_files = glob.glob('output/*.csv')
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**Donn√©es brutes (data/)**")
            if data_files:
                for f in data_files:
                    st.success(f"‚úÖ {os.path.basename(f)}")
            else:
                st.warning("Aucun fichier CSV trouv√©")
        
        with col2:
            st.write("**Donn√©es trait√©es (output/)**")
            if output_files:
                for f in output_files:
                    st.success(f"‚úÖ {os.path.basename(f)}")
            else:
                st.info("Aucun fichier trait√©")

    # Module Import
    elif selected_tab == "üì§ Import de Donn√©es":
        st.header("üì§ Import et Gestion des Donn√©es")
        
        # Upload multiple files
        uploaded_files = st.file_uploader(
            "S√©lectionnez vos fichiers CSV",
            type=['csv'],
            accept_multiple_files=True,
            help="Vous pouvez uploader plusieurs fichiers CSV. Le syst√®me d√©tectera automatiquement le type de donn√©es."
        )
        
        if uploaded_files:
            if st.button("üì• Traiter les Fichiers", type="primary"):
                with st.spinner("Traitement des fichiers en cours..."):
                    success = analytics.process_uploaded_files(uploaded_files)
                    if success:
                        st.balloons()
                        st.success("üéâ Tous les fichiers ont √©t√© upload√©s avec succ√®s!")
                        
                        # Aper√ßu des donn√©es
                        st.subheader("üëÄ Aper√ßu des Donn√©es")
                        datasets = analytics.load_data()
                        
                        for data_type, df in datasets.items():
                            with st.expander(f"üìã {data_type.title()} ({len(df)} lignes)"):
                                st.dataframe(df.head())
                                st.info(f"Colonnes d√©tect√©es: {', '.join(df.columns)}")
        
        # Exemples de format attendu
        st.subheader("üìã Formats de Donn√©es Attendus")
        
        format_examples = {
            "üë• Clients": ["customer_id", "age", "city", "client_type", "signup_date"],
            "üõçÔ∏è Produits": ["product_id", "name", "category", "price"],
            "üí∞ Ventes": ["order_id", "customer_id", "product_id", "order_date", "quantity", "total_amount"],
            "üì¢ Marketing": ["date", "channel", "campaign", "impressions", "clicks", "conversions", "cost", "revenue"]
        }
        
        cols = st.columns(2)
        for i, (data_type, columns) in enumerate(format_examples.items()):
            with cols[i % 2]:
                st.write(f"**{data_type}**")
                for col in columns:
                    st.write(f"‚Ä¢ {col}")

    # Module M2: Nettoyage
    elif selected_tab == "üßπ M2: Nettoyage":
        st.header("üßπ M2: Nettoyage et Standardisation des Donn√©es")
        
        if st.button("üöÄ Lancer le Nettoyage", type="primary"):
            with st.spinner("Nettoyage des donn√©es en cours..."):
                # Charger les donn√©es brutes
                raw_datasets = analytics.load_data()
                
                if not raw_datasets:
                    st.error("‚ùå Aucune donn√©e trouv√©e. Veuillez d'abord importer vos fichiers.")
                else:
                    # Nettoyage et standardisation
                    cleaned_datasets = analytics.clean_and_standardize_data(raw_datasets)
                    
                    if cleaned_datasets:
                        st.success("‚úÖ Nettoyage termin√© avec succ√®s!")
                        
                        # Affichage des r√©sultats
                        st.subheader("üìä R√©sultats du Nettoyage")
                        
                        for data_type, df in cleaned_datasets.items():
                            with st.expander(f"üìã {data_type.title()} - Donn√©es Nettoy√©es"):
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.metric("Lignes", len(df))
                                with col2:
                                    st.metric("Colonnes", len(df.columns))
                                
                                st.dataframe(df.head())
                                
                                # Statistiques de qualit√©
                                st.write("**Qualit√© des Donn√©es**")
                                quality_info = []
                                for col in df.columns:
                                    null_pct = (df[col].isnull().sum() / len(df)) * 100
                                    quality_info.append({
                                        "Colonne": col,
                                        "Valeurs Nulles (%)": f"{null_pct:.1f}%",
                                        "Type": str(df[col].dtype)
                                    })
                                
                                st.dataframe(pd.DataFrame(quality_info), use_container_width=True)
                    else:
                        st.warning("‚ö†Ô∏è Aucune donn√©e n'a pu √™tre nettoy√©e.")
        
        # Affichage des fichiers nettoy√©s existants
        cleaned_files = glob.glob('output/*_clean.csv')
        if cleaned_files:
            st.subheader("üìÇ Fichiers Nettoy√©s Disponibles")
            for file_path in cleaned_files:
                filename = os.path.basename(file_path)
                with st.expander(f"üìÑ {filename}"):
                    try:
                        df = pd.read_csv(file_path)
                        st.dataframe(df.head())
                        st.download_button(
                            f"‚¨áÔ∏è T√©l√©charger {filename}",
                            df.to_csv(index=False),
                            filename,
                            "text/csv"
                        )
                    except Exception as e:
                        st.error(f"Erreur lors de la lecture de {filename}: {str(e)}")

    # Module M3: Segmentation
    elif selected_tab == "üë• M3: Segmentation":
        st.header("üë• M3: Segmentation Clients (RFM Analysis)")
        
        if st.button("üéØ Lancer la Segmentation", type="primary"):
            with st.spinner("Analyse RFM en cours..."):
                try:
                    customers_data = pd.read_csv('output/customers_clean.csv')
                    sales_data = pd.read_csv('output/sales_clean.csv')
                    
                    segments_data, silhouette_score, optimal_k = analytics.perform_customer_segmentation(customers_data, sales_data)
                    
                    if segments_data is not None:
                        st.success(f"‚úÖ Segmentation termin√©e! {optimal_k} segments identifi√©s (Score Silhouette: {silhouette_score:.3f})")
                        
                        # M√©triques de segmentation
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Segments", optimal_k)
                        with col2:
                            st.metric("Score Silhouette", f"{silhouette_score:.3f}")
                        with col3:
                            st.metric("Clients Segment√©s", len(segments_data))
                        with col4:
                            st.metric("Features Utilis√©es", "RFM + √Çge")
                        
                        # Visualisations
                        st.subheader("üìä Visualisations des Segments")
                        
                        # Distribution des segments
                        fig_dist = px.pie(
                            values=segments_data['cluster'].value_counts().values,
                            names=[f'Segment {i}' for i in segments_data['cluster'].value_counts().index],
                            title="Distribution des Segments Clients"
                        )
                        st.plotly_chart(fig_dist, use_container_width=True)
                        
                        # Analyse RFM par segment
                        st.subheader("üîç Analyse RFM par Segment")
                        segment_summary = segments_data.groupby('cluster').agg({
                            'recency': 'mean',
                            'frequency': 'mean',
                            'monetary': 'mean'
                        }).round(2)
                        
                        st.dataframe(segment_summary, use_container_width=True)
                        
                        # Scatter plot RFM
                        fig_scatter = px.scatter_3d(
                            segments_data,
                            x='frequency',
                            y='monetary',
                            z='recency',
                            color='cluster',
                            title="Analyse RFM 3D par Segment",
                            labels={
                                'frequency': 'Fr√©quence',
                                'monetary': 'Valeur Mon√©taire (Ar)',
                                'recency': 'R√©cence (jours)'
                            }
                        )
                        st.plotly_chart(fig_scatter, use_container_width=True)
                        
                        # Matrice de corr√©lation
                        st.subheader("üîó Matrice de Corr√©lation des Variables RFM")
                        corr_matrix = segments_data[['recency', 'frequency', 'monetary']].corr()
                        fig_corr = px.imshow(
                            corr_matrix,
                            title="Matrice de Corr√©lation RFM",
                            color_continuous_scale="RdBu"
                        )
                        st.plotly_chart(fig_corr, use_container_width=True)
                        
                        # Tableau d√©taill√©
                        st.subheader("üìã Donn√©es de Segmentation")
                        st.dataframe(segments_data, use_container_width=True)
                        
                        # T√©l√©chargement
                        csv_data = segments_data.to_csv(index=False)
                        st.download_button(
                            "‚¨áÔ∏è T√©l√©charger les Segments",
                            csv_data,
                            "customer_segments.csv",
                            "text/csv"
                        )
                    
                except FileNotFoundError:
                    st.error("‚ùå Fichiers de donn√©es manquants. Veuillez d'abord ex√©cuter M2 (Nettoyage).")
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la segmentation: {str(e)}")

    # Module M4: Personas
    elif selected_tab == "üé≠ M4: Personas":
        st.header("üé≠ M4: Cr√©ation de Personas Clients")
        
        if st.button("üë§ G√©n√©rer les Personas", type="primary"):
            with st.spinner("Cr√©ation des personas en cours..."):
                try:
                    customers_data = pd.read_csv('output/customers_clean.csv')
                    sales_data = pd.read_csv('output/sales_clean.csv')
                    segments_data = pd.read_csv('output/customer_segments.csv')
                    
                    # Chargement optionnel des produits
                    try:
                        products_data = pd.read_csv('output/products_clean.csv')
                    except:
                        products_data = pd.DataFrame()
                    
                    personas = analytics.create_customer_personas(segments_data, customers_data, sales_data, products_data)
                    
                    if personas:
                        st.success(f"‚úÖ {len(personas)} personas cr√©√©s avec succ√®s!")
                        
                        # Vue d'ensemble des personas
                        st.subheader("üë• Vue d'Ensemble des Personas")
                        
                        personas_summary = []
                        for segment_name, persona_data in personas.items():
                            personas_summary.append({
                                "Segment": segment_name.replace('_', ' ').title(),
                                "Taille": persona_data['size'],
                                "% Base": f"{persona_data['size']/len(customers_data)*100:.1f}%",
                                "Valeur Moy.": f"{persona_data['avg_monetary']:,.0f} Ar",
                                "Fr√©quence": f"{persona_data['avg_frequency']:.1f}",
                                "CA Total": f"{persona_data['total_revenue']:,.0f} Ar"
                            })
                        
                        summary_df = pd.DataFrame(personas_summary)
                        st.dataframe(summary_df, use_container_width=True)
                        
                        # Visualisations comparatives
                        st.subheader("üìä Comparaison des Personas")
                        
                        # Graphique en barres - Valeur par segment
                        fig_value = px.bar(
                            summary_df,
                            x="Segment",
                            y=[col for col in summary_df.columns if "Valeur" in col or "CA" in col],
                            title="Valeur Mon√©taire par Segment"
                        )
                        st.plotly_chart(fig_value, use_container_width=True)
                        
                        # Graphique radar pour comparaison multidimensionnelle
                        if len(personas) > 1:
                            radar_data = []
                            for segment_name, persona_data in personas.items():
                                radar_data.append({
                                    'Segment': segment_name.replace('_', ' ').title(),
                                    'Taille_Normalis√©e': persona_data['size'] / max(p['size'] for p in personas.values()),
                                    'Fr√©quence_Normalis√©e': persona_data['avg_frequency'] / max(p['avg_frequency'] for p in personas.values()),
                                    'Valeur_Normalis√©e': persona_data['avg_monetary'] / max(p['avg_monetary'] for p in personas.values()),
                                    'R√©cence_Normalis√©e': 1 - (persona_data['avg_recency'] / max(p['avg_recency'] for p in personas.values()))
                                })
                            
                            radar_df = pd.DataFrame(radar_data)
                            
                            fig_radar = go.Figure()
                            
                            for _, row in radar_df.iterrows():
                                fig_radar.add_trace(go.Scatterpolar(
                                    r=[row['Taille_Normalis√©e'], row['Fr√©quence_Normalis√©e'], 
                                       row['Valeur_Normalis√©e'], row['R√©cence_Normalis√©e']],
                                    theta=['Taille', 'Fr√©quence', 'Valeur', 'R√©cence'],
                                    fill='toself',
                                    name=row['Segment']
                                ))
                            
                            fig_radar.update_layout(
                                polar=dict(
                                    radialaxis=dict(
                                        visible=True,
                                        range=[0, 1]
                                    )),
                                title="Comparaison Multidimensionnelle des Personas"
                            )
                            
                            st.plotly_chart(fig_radar, use_container_width=True)
                        
                        # Profils d√©taill√©s
                        st.subheader("üîç Profils D√©taill√©s des Personas")
                        
                        for segment_name, persona_data in personas.items():
                            with st.expander(f"üë§ {segment_name.replace('_', ' ').title()}", expanded=True):
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric("Taille du Segment", f"{persona_data['size']} clients")
                                    st.metric("√Çge Moyen", f"{persona_data.get('avg_age', 0):.0f} ans" if persona_data.get('avg_age') else "N/A")
                                
                                with col2:
                                    st.metric("Valeur Moyenne", f"{persona_data['avg_monetary']:,.0f} Ar")
                                    st.metric("Fr√©quence", f"{persona_data['avg_frequency']:.1f} commandes")
                                
                                with col3:
                                    st.metric("CA Total", f"{persona_data['total_revenue']:,.0f} Ar")
                                    st.metric("Ville Principale", persona_data.get('top_city', 'N/A'))
                                
                                # Cat√©gories pr√©f√©r√©es
                                if persona_data.get('top_categories'):
                                    st.write("**üõçÔ∏è Cat√©gories Pr√©f√©r√©es:**")
                                    categories_df = pd.DataFrame(
                                        list(persona_data['top_categories'].items()),
                                        columns=['Cat√©gorie', 'Commandes']
                                    )
                                    st.dataframe(categories_df, use_container_width=True)
                                
                                # Recommandations marketing
                                st.write("**üí° Recommandations Marketing:**")
                                if "0" in segment_name or "High" in segment_name:
                                    st.info("üéØ Clients Premium: Offres exclusives, service VIP, produits haut de gamme")
                                elif "1" in segment_name or "Medium" in segment_name:
                                    st.info("üìà Clients R√©guliers: Programmes fid√©lit√©, cross-selling, offres group√©es")
                                else:
                                    st.info("üå± Clients √† D√©velopper: Promotions attractives, onboarding, content marketing")
                        
                        # Sauvegarde des personas
                        personas_df = pd.DataFrame.from_dict(personas, orient='index')
                        personas_csv = personas_df.to_csv()
                        st.download_button(
                            "‚¨áÔ∏è T√©l√©charger les Personas",
                            personas_csv,
                            "customer_personas.csv",
                            "text/csv"
                        )
                    
                except FileNotFoundError as e:
                    st.error(f"‚ùå Fichiers manquants: {str(e)}. Veuillez d'abord ex√©cuter les modules pr√©c√©dents.")
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la cr√©ation des personas: {str(e)}")

    # Module M5: Marketing KPIs  
    elif selected_tab == "üìä M5: Marketing KPIs":
        st.header("üìä M5: Analyse des KPIs Marketing")
        
        if st.button("üìà Calculer les KPIs", type="primary"):
            with st.spinner("Calcul des KPIs marketing..."):
                try:
                    marketing_data = pd.read_csv('output/marketing_clean.csv')
                    
                    kpis_df, kpi_summary, benchmarks = analytics.calculate_marketing_kpis(marketing_data)
                    
                    if kpis_df is not None:
                        st.success("‚úÖ KPIs calcul√©s avec succ√®s!")
                        
                        # M√©triques principales
                        st.subheader("üéØ KPIs Globaux")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric(
                                "Impressions", 
                                f"{kpi_summary['total_impressions']:,.0f}",
                                help="Nombre total d'impressions"
                            )
                        with col2:
                            st.metric(
                                "CTR", 
                                f"{kpi_summary['overall_ctr']*100:.2f}%",
                                delta=f"Obj: {analytics.targets['ctr_min']*100:.1f}%"
                            )
                        with col3:
                            st.metric(
                                "CPC", 
                                f"{kpi_summary['overall_cpc']:,.0f} Ar",
                                delta=f"Obj: ‚â§{analytics.targets['cpc_max']:.0f} Ar"
                            )
                        with col4:
                            st.metric(
                                "ROAS", 
                                f"{kpi_summary['overall_roas']:.2f}x",
                                delta=f"Obj: ‚â•{analytics.targets['roi_min']:.1f}x"
                            )
                        
                        # Tableau de bord des KPIs d√©taill√©s
                        st.subheader("üìã Tableau de Bord D√©taill√©")
                        
                        detailed_metrics = [
                            {"KPI": "Impressions", "Valeur": f"{kpi_summary['total_impressions']:,.0f}", "Description": "Nombre total de vues"},
                            {"KPI": "Clics", "Valeur": f"{kpi_summary['total_clicks']:,.0f}", "Description": "Nombre total de clics"},
                            {"KPI": "Conversions", "Valeur": f"{kpi_summary['total_conversions']:,.0f}", "Description": "Nombre total de conversions"},
                            {"KPI": "CTR", "Valeur": f"{kpi_summary['overall_ctr']*100:.2f}%", "Description": "Taux de clic"},
                            {"KPI": "CVR", "Valeur": f"{kpi_summary['overall_cvr']*100:.2f}%", "Description": "Taux de conversion"},
                            {"KPI": "CPC", "Valeur": f"{kpi_summary['overall_cpc']:,.0f} Ar", "Description": "Co√ªt par clic"},
                            {"KPI": "CPA", "Valeur": f"{kpi_summary['overall_cpa']:,.0f} Ar", "Description": "Co√ªt par acquisition"},
                            {"KPI": "ROAS", "Valeur": f"{kpi_summary['overall_roas']:.2f}x", "Description": "Retour sur investissement publicitaire"}
                        ]
                        
                        metrics_df = pd.DataFrame(detailed_metrics)
                        st.dataframe(metrics_df, use_container_width=True)
                        
                        # Benchmarks vs Objectifs
                        st.subheader("üéØ Performance vs Objectifs")
                        
                        benchmarks_df = pd.DataFrame(benchmarks)
                        
                        # Coloration conditionnelle
                        def color_status(val):
                            if val == 'Atteint':
                                return 'background-color: #d4edda'
                            else:
                                return 'background-color: #f8d7da'
                        
                        styled_benchmarks = benchmarks_df.style.applymap(color_status, subset=['Statut'])
                        st.dataframe(styled_benchmarks, use_container_width=True)
                        
                        # Visualisations des KPIs
                        st.subheader("üìä Visualisations des Performances")
                        
                        # √âvolution temporelle des KPIs
                        if 'date' in kpis_df.columns:
                            kpis_df['date'] = pd.to_datetime(kpis_df['date'])
                            
                            # Graphique temporel multi-KPIs
                            fig_timeline = make_subplots(
                                rows=2, cols=2,
                                subplot_titles=('CTR (%)', 'CPC (Ar)', 'Conversions', 'ROAS'),
                                vertical_spacing=0.1
                            )
                            
                            # CTR
                            fig_timeline.add_trace(
                                go.Scatter(x=kpis_df['date'], y=kpis_df['ctr']*100, name='CTR'),
                                row=1, col=1
                            )
                            
                            # CPC
                            fig_timeline.add_trace(
                                go.Scatter(x=kpis_df['date'], y=kpis_df['cpc'], name='CPC'),
                                row=1, col=2
                            )
                            
                            # Conversions
                            fig_timeline.add_trace(
                                go.Scatter(x=kpis_df['date'], y=kpis_df['conversions'], name='Conversions'),
                                row=2, col=1
                            )
                            
                            # ROAS
                            if 'roas' in kpis_df.columns:
                                fig_timeline.add_trace(
                                    go.Scatter(x=kpis_df['date'], y=kpis_df['roas'], name='ROAS'),
                                    row=2, col=2
                                )
                            
                            fig_timeline.update_layout(height=600, title_text="√âvolution des KPIs Marketing")
                            st.plotly_chart(fig_timeline, use_container_width=True)
                        
                        # Performance par canal
                        if 'channel' in kpis_df.columns:
                            channel_perf = kpis_df.groupby('channel').agg({
                                'impressions': 'sum',
                                'clicks': 'sum',
                                'conversions': 'sum',
                                'cost': 'sum',
                                'revenue': 'sum' if 'revenue' in kpis_df.columns else lambda x: 0
                            }).reset_index()
                            
                            channel_perf['ctr'] = channel_perf['clicks'] / channel_perf['impressions']
                            channel_perf['cpc'] = channel_perf['cost'] / channel_perf['clicks']
                            channel_perf['roas'] = channel_perf['revenue'] / channel_perf['cost']
                            
                            fig_channels = px.bar(
                                channel_perf,
                                x='channel',
                                y=['impressions', 'clicks', 'conversions'],
                                title='Performance par Canal Marketing',
                                barmode='group'
                            )
                            st.plotly_chart(fig_channels, use_container_width=True)
                        
                        # Matrice de corr√©lation des KPIs
                        st.subheader("üîó Corr√©lations entre KPIs")
                        numeric_kpis = kpis_df.select_dtypes(include=[np.number])
                        if len(numeric_kpis.columns) > 1:
                            corr_matrix = numeric_kpis.corr()
                            
                            fig_corr = px.imshow(
                                corr_matrix,
                                title="Matrice de Corr√©lation des KPIs",
                                color_continuous_scale="RdBu",
                                aspect="auto"
                            )
                            st.plotly_chart(fig_corr, use_container_width=True)
                        
                        # Recommandations automatiques
                        st.subheader("üí° Recommandations Automatiques")
                        
                        recommendations = []
                        
                        if kpi_summary['overall_ctr'] < analytics.targets['ctr_min']:
                            recommendations.append("üéØ **CTR faible**: Optimiser les cr√©atifs publicitaires et le ciblage")
                        
                        if kpi_summary['overall_cpc'] > analytics.targets['cpc_max']:
                            recommendations.append("üí∞ **CPC √©lev√©**: Revoir la strat√©gie d'ench√®res et affiner le ciblage")
                        
                        if kpi_summary['overall_roas'] < analytics.targets['roi_min']:
                            recommendations.append("üìà **ROAS insuffisant**: Analyser le funnel de conversion et optimiser les landing pages")
                        
                        if kpi_summary['overall_cvr'] < analytics.targets['conversion_rate_target']:
                            recommendations.append("üîÑ **Taux de conversion faible**: Am√©liorer l'exp√©rience utilisateur et les call-to-action")
                        
                        if not recommendations:
                            st.success("üéâ Excellente performance! Tous les objectifs sont atteints.")
                        else:
                            for rec in recommendations:
                                st.warning(rec)
                        
                        # T√©l√©chargements
                        st.subheader("‚¨áÔ∏è T√©l√©chargements")
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            kpis_csv = kpis_df.to_csv(index=False)
                            st.download_button(
                                "üìä T√©l√©charger KPIs D√©taill√©s",
                                kpis_csv,
                                "campaign_kpis.csv",
                                "text/csv"
                            )
                        
                        with col2:
                            benchmarks_csv = benchmarks_df.to_csv(index=False)
                            st.download_button(
                                "üéØ T√©l√©charger Benchmarks",
                                benchmarks_csv,
                                "kpi_benchmarks.csv",
                                "text/csv"
                            )
                    
                except FileNotFoundError:
                    st.error("‚ùå Fichier marketing_clean.csv manquant. Veuillez d'abord ex√©cuter M2 (Nettoyage).")
                except Exception as e:
                    st.error(f"‚ùå Erreur lors du calcul des KPIs: {str(e)}")

    # Module M6: Analyse Pr√©dictive
    elif selected_tab == "üîÆ M6: Analyse Pr√©dictive":
        st.header("üîÆ M6: Mod√®le Pr√©dictif de Churn")
        
        if st.button("ü§ñ Entra√Æner le Mod√®le", type="primary"):
            with st.spinner("Entra√Ænement du mod√®le pr√©dictif..."):
                try:
                    customers_data = pd.read_csv('output/customers_clean.csv')
                    sales_data = pd.read_csv('output/sales_clean.csv')
                    
                    churn_data, feature_importance, auc_score = analytics.build_predictive_model(customers_data, sales_data)
                    
                    if churn_data is not None:
                        st.success(f"‚úÖ Mod√®le entra√Æn√© avec succ√®s! Score AUC: {auc_score:.3f}")
                        
                        # M√©triques du mod√®le
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Score AUC", f"{auc_score:.3f}")
                        with col2:
                            st.metric("Clients Analys√©s", len(churn_data))
                        with col3:
                            churn_rate = (churn_data['is_churned'].sum() / len(churn_data)) * 100
                            st.metric("Taux de Churn", f"{churn_rate:.1f}%")
                        with col4:
                            high_risk = len(churn_data[churn_data['churn_risk'] == '√âlev√©'])
                            st.metric("Clients √† Risque", high_risk)
                        
                        # Distribution du risque de churn
                        st.subheader("üìä Distribution du Risque de Churn")
                        
                        risk_counts = churn_data['churn_risk'].value_counts()
                        fig_risk = px.pie(
                            values=risk_counts.values,
                            names=risk_counts.index,
                            title="R√©partition des Clients par Niveau de Risque",
                            color_discrete_map={
                                'Faible': '#28a745',
                                'Moyen': '#ffc107', 
                                '√âlev√©': '#dc3545'
                            }
                        )
                        st.plotly_chart(fig_risk, use_container_width=True)
                        
                        # Histogramme des probabilit√©s de churn
                        fig_hist = px.histogram(
                            churn_data,
                            x='churn_probability',
                            nbins=20,
                            title="Distribution des Probabilit√©s de Churn",
                            labels={'churn_probability': 'Probabilit√© de Churn', 'count': 'Nombre de Clients'}
                        )
                        st.plotly_chart(fig_hist, use_container_width=True)
                        
                        # Importance des variables
                        st.subheader("üéØ Importance des Variables")
                        
                        fig_importance = px.bar(
                            feature_importance,
                            x='importance',
                            y='feature',
                            orientation='h',
                            title="Importance des Variables dans la Pr√©diction de Churn"
                        )
                        st.plotly_chart(fig_importance, use_container_width=True)
                        
                        # Analyse par segment de risque
                        st.subheader("üîç Analyse par Segment de Risque")
                        
                        for risk_level in ['√âlev√©', 'Moyen', 'Faible']:
                            risk_data = churn_data[churn_data['churn_risk'] == risk_level]
                            
                            if len(risk_data) > 0:
                                with st.expander(f"üéØ Clients √† Risque {risk_level} ({len(risk_data)} clients)", expanded=(risk_level == '√âlev√©')):
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        st.metric("R√©cence Moyenne", f"{risk_data['recency'].mean():.0f} jours")
                                        st.metric("Probabilit√© Moyenne", f"{risk_data['churn_probability'].mean():.1%}")
                                    
                                    with col2:
                                        st.metric("Fr√©quence Moyenne", f"{risk_data['frequency'].mean():.1f}")
                                        st.metric("D√©pense Totale Moy.", f"{risk_data['total_spent'].mean():,.0f} Ar")
                                    
                                    with col3:
                                        st.metric("Panier Moyen", f"{risk_data['avg_order_value'].mean():,.0f} Ar")
                                        if 'age' in risk_data.columns:
                                            st.metric("√Çge Moyen", f"{risk_data['age'].mean():.0f} ans")
                                    
                                    # Recommandations par niveau de risque
                                    st.write("**üí° Recommandations:**")
                                    if risk_level == '√âlev√©':
                                        st.error("üö® **Actions Urgentes**: Contact imm√©diat, offres exclusives, support personnalis√©")
                                    elif risk_level == 'Moyen':
                                        st.warning("‚ö†Ô∏è **Surveillance Active**: Campagnes de r√©tention, programmes fid√©lit√©, enqu√™tes satisfaction")
                                    else:
                                        st.success("‚úÖ **Maintien de l'Engagement**: Communication r√©guli√®re, programmes d'ambassadeurs, cross-selling")
                                    
                                    # Top clients √† risque pour le niveau √©lev√©
                                    if risk_level == '√âlev√©' and len(risk_data) > 0:
                                        st.write("**üë• Clients Prioritaires:**")
                                        priority_clients = risk_data.nlargest(10, 'total_spent')[['customer_id', 'churn_probability', 'total_spent', 'recency']]
                                        priority_clients['churn_probability'] = priority_clients['churn_probability'].apply(lambda x: f"{x:.1%}")
                                        priority_clients['total_spent'] = priority_clients['total_spent'].apply(lambda x: f"{x:,.0f} Ar")
                                        st.dataframe(priority_clients, use_container_width=True)
                        
                        # Matrice de confusion visuelle (si applicable)
                        if auc_score > 0:
                            st.subheader("üìà Performance du Mod√®le")
                            
                            # Seuils de probabilit√© pour analyse
                            thresholds = [0.3, 0.5, 0.7]
                            threshold_analysis = []
                            
                            for threshold in thresholds:
                                predicted_churn = (churn_data['churn_probability'] >= threshold).astype(int)
                                actual_churn = churn_data['is_churned']
                                
                                tp = ((predicted_churn == 1) & (actual_churn == 1)).sum()
                                fp = ((predicted_churn == 1) & (actual_churn == 0)).sum()
                                tn = ((predicted_churn == 0) & (actual_churn == 0)).sum()
                                fn = ((predicted_churn == 0) & (actual_churn == 1)).sum()
                                
                                precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                                recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                                accuracy = (tp + tn) / len(churn_data)
                                
                                threshold_analysis.append({
                                    'Seuil': threshold,
                                    'Pr√©cision': f"{precision:.1%}",
                                    'Rappel': f"{recall:.1%}",
                                    'Exactitude': f"{accuracy:.1%}",
                                    'Pr√©dictions Positives': tp + fp
                                })
                            
                            threshold_df = pd.DataFrame(threshold_analysis)
                            st.dataframe(threshold_df, use_container_width=True)
                        
                        # Plans d'action par segment
                        st.subheader("üìã Plans d'Action Recommand√©s")
                        
                        action_plans = {
                            "üö® Risque √âlev√©": [
                                "Appel t√©l√©phonique dans les 24h",
                                "Offre de r√©activation exclusive (-30%)",
                                "Invitation √† un √©v√©nement VIP",
                                "Enqu√™te de satisfaction personnalis√©e",
                                "Attribution d'un account manager d√©di√©"
                            ],
                            "‚ö†Ô∏è Risque Moyen": [
                                "Email de r√©tention personnalis√©",
                                "Recommandations de produits bas√©es sur l'historique",
                                "Invitation au programme de fid√©lit√©",
                                "Offre de bundling produits",
                                "Newsletter avec contenu exclusif"
                            ],
                            "‚úÖ Risque Faible": [
                                "Communication marketing standard",
                                "Sollicitation pour avis/t√©moignages",
                                "Invitation programme parrainage",
                                "Cross-selling intelligent",
                                "Enqu√™te de satisfaction trimestrielle"
                            ]
                        }
                        
                        for risk_category, actions in action_plans.items():
                            with st.expander(f"{risk_category} - Plan d'Action"):
                                for i, action in enumerate(actions, 1):
                                    st.write(f"{i}. {action}")
                        
                        # T√©l√©chargements
                        st.subheader("‚¨áÔ∏è Exports")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            churn_csv = churn_data.to_csv(index=False)
                            st.download_button(
                                "üìä T√©l√©charger Pr√©dictions",
                                churn_csv,
                                "churn_predictions.csv",
                                "text/csv"
                            )
                        
                        with col2:
                            importance_csv = feature_importance.to_csv(index=False)
                            st.download_button(
                                "üéØ T√©l√©charger Importance Variables",
                                importance_csv,
                                "feature_importance.csv",
                                "text/csv"
                            )
                    
                except FileNotFoundError:
                    st.error("‚ùå Fichiers de donn√©es manquants. Veuillez d'abord ex√©cuter les modules pr√©c√©dents.")
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'analyse pr√©dictive: {str(e)}")
        
        # --- Section: Pr√©diction d'objectifs commerciaux (M6 UI) ---
        st.markdown("---")
        render_sales_objective_prediction_section()

        # --- Section: Entra√Æner le mod√®le Objectif Commercial (√† partir d'un CSV import√©) ---
        st.markdown("---")
        with st.expander("‚öôÔ∏è Entra√Æner le Mod√®le d'Objectif Commercial (√† partir d'un fichier import√©)"):
            st.caption(
                "Le fichier CSV doit contenir les colonnes: "
                + ", ".join(EXPECTED_FEATURES)
                + f" et la cible binaire '{TARGET_NAME}'"
            )

            uploaded_csv = st.file_uploader("Importer un CSV d'entra√Ænement", type=["csv"], key="m6_obj_train_csv")
            manual_path = st.text_input("ou Chemin d'un CSV existant", value="")
            output_model_path = st.text_input(
                "Chemin de sortie du mod√®le (.pkl)", value="models/modele_objectif_commercial.pkl"
            )

            if st.button("üöÄ Entra√Æner et Sauvegarder le Mod√®le", type="primary"):
                try:
                    data_path = None
                    if uploaded_csv is not None:
                        os.makedirs("output", exist_ok=True)
                        tmp_path = os.path.join("output", "objective_training.csv")
                        with open(tmp_path, "wb") as f:
                            f.write(uploaded_csv.getbuffer())
                        data_path = tmp_path
                    elif manual_path:
                        data_path = manual_path

                    if data_path is None:
                        st.error("Veuillez importer un CSV ou renseigner un chemin valide.")
                    else:
                        # Validation rapide des colonnes
                        df_check = pd.read_csv(data_path)
                        missing = [c for c in EXPECTED_FEATURES + [TARGET_NAME] if c not in df_check.columns]
                        if missing:
                            st.error(
                                f"Colonnes manquantes: {missing}. Colonnes attendues: {EXPECTED_FEATURES + [TARGET_NAME]}"
                            )
                        else:
                            if train_objective_model is None:
                                st.error("La fonction d'entra√Ænement n'est pas disponible. Red√©marrez l'app et r√©essayez.")
                            else:
                                path = train_objective_model(data_path, output_model_path)
                                st.success(f"‚úÖ Mod√®le entra√Æn√© et sauvegard√©: {path}")
                                st.info("Revenez √† la section de pr√©diction ci-dessus pour l'utiliser.")
                except Exception as e:
                    st.error(f"‚ùå √âchec de l'entra√Ænement: {str(e)}")

    # Module Dashboard Complet
    elif selected_tab == "üìà Dashboard Complet":
        st.header("üìà Dashboard Analytics Complet")
        
        try:
            # Chargement de tous les fichiers disponibles (par d√©faut depuis output/)
            customers_data = pd.read_csv('output/customers_clean.csv') if os.path.exists('output/customers_clean.csv') else pd.DataFrame()
            sales_data = pd.read_csv('output/sales_clean.csv') if os.path.exists('output/sales_clean.csv') else pd.DataFrame()
            marketing_data = pd.read_csv('output/marketing_clean.csv') if os.path.exists('output/marketing_clean.csv') else pd.DataFrame()
            segments_data = pd.read_csv('output/customer_segments.csv') if os.path.exists('output/customer_segments.csv') else pd.DataFrame()

            # Option: utiliser des fichiers import√©s directement pour ce dashboard
            with st.expander("üì• Importer des CSV pour ce Dashboard (remplace les donn√©es par d√©faut)"):
                uploaded_files = st.file_uploader(
                    "Importer des fichiers CSV", type=["csv"], accept_multiple_files=True, key="dash_manual_csvs"
                )
                if uploaded_files:
                    if analytics.process_uploaded_files(uploaded_files):
                        datasets = analytics.load_data()
                        cleaned = analytics.clean_and_standardize_data(datasets)
                        # Remplacer les DataFrames si disponibles
                        if 'customers' in cleaned:
                            customers_data = cleaned['customers']
                        if 'sales' in cleaned:
                            sales_data = cleaned['sales']
                        if 'marketing' in cleaned:
                            marketing_data = cleaned['marketing']
                        # segments_data: g√©n√©r√© par M3, pas directement depuis uploads
                        st.success("Les donn√©es import√©es ont √©t√© appliqu√©es au dashboard.")
                        st.caption(
                            f"Clients: {0 if customers_data is None or customers_data.empty else len(customers_data)} | "
                            f"Ventes: {0 if sales_data is None or sales_data.empty else len(sales_data)} | "
                            f"Marketing: {0 if marketing_data is None or marketing_data.empty else len(marketing_data)}"
                        )
            
            if customers_data.empty and sales_data.empty:
                st.warning("üì§ Aucune donn√©e disponible. Veuillez d'abord importer et traiter vos donn√©es.")
                st.stop()
            
            # KPIs G√©n√©raux
            st.subheader("üéØ KPIs G√©n√©raux")
            # Param√®tre: prix unitaire par d√©faut si non fourni dans ventes
            default_unit_price = st.number_input(
                "üíµ Prix unitaire par d√©faut (Ar) si absent dans les ventes",
                min_value=0, max_value=10_000_000, value=30_000, step=1_000,
                help="Utilis√© pour calculer total_amount = unit_price * quantity quand unit_price/total_amount sont manquants."
            )
            # Persister la valeur de r√©f√©rence
            try:
                st.session_state['default_unit_price'] = float(default_unit_price)
            except Exception:
                st.session_state['default_unit_price'] = 0.0

            # Construire et persister un sales_processed unique pour tout le Dashboard
            has_sales = sales_data is not None and not sales_data.empty
            sales_processed = sales_data.copy() if has_sales else pd.DataFrame()
            if not sales_processed.empty:
                unit_cols = [c for c in sales_processed.columns if c in ['unit_price', 'price', 'prix']]
                qty_cols = [c for c in sales_processed.columns if c in ['quantity', 'qty', 'quantite', 'quantit√©']]
                qt = pd.Series(0, index=sales_processed.index)
                if qty_cols:
                    qt = pd.to_numeric(sales_processed[qty_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(0)
                if unit_cols:
                    up = pd.to_numeric(sales_processed[unit_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(float(default_unit_price))
                else:
                    up = pd.Series(float(default_unit_price), index=sales_processed.index)
                if 'total_amount' not in sales_processed.columns:
                    sales_processed['total_amount'] = (up * qt)
                else:
                    ta_clean = pd.to_numeric(
                        sales_processed['total_amount'].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'),
                        errors='coerce'
                    )
                    sales_processed['total_amount'] = ta_clean.where(ta_clean.notna() & (ta_clean > 0), (up * qt))
                # Dates
                if 'order_date' in sales_processed.columns:
                    sales_processed['order_date'] = pd.to_datetime(sales_processed['order_date'], errors='coerce')
                st.session_state['sales_processed'] = sales_processed.copy()
            
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            
            with col1:
                total_customers = len(customers_data) if not customers_data.empty else 0
                st.metric("üë• Clients Total", f"{total_customers:,}")
            
            with col2:
                total_revenue = 0.0
                has_sales = sales_data is not None and not sales_data.empty
                if has_sales:
                    sd = st.session_state.get('sales_processed', sales_data).copy()
                    unit_cols = [c for c in sd.columns if c in ['unit_price', 'price', 'prix']]
                    qty_cols = [c for c in sd.columns if c in ['quantity', 'qty', 'quantite', 'quantit√©']]
                    # Pr√©parer qt et up
                    qt = pd.Series(0, index=sd.index)
                    if qty_cols:
                        qt = pd.to_numeric(sd[qty_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(0)
                    if unit_cols:
                        up = pd.to_numeric(sd[unit_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(float(default_unit_price))
                    else:
                        up = pd.Series(float(default_unit_price), index=sd.index)
                    # Construire/Nettoyer total_amount
                    if 'total_amount' not in sd.columns:
                        sd['total_amount'] = (up * qt)
                    else:
                        ta_clean = pd.to_numeric(
                            sd['total_amount'].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'),
                            errors='coerce'
                        )
                        fill_series = (up * qt)
                        sd['total_amount'] = ta_clean.where(ta_clean.notna() & (ta_clean > 0), fill_series)
                    # S√©rie finale propre
                    ta_series = pd.to_numeric(sd['total_amount'], errors='coerce').fillna(0)
                    total_revenue = float(ta_series.sum())
                st.metric("üí∞ CA Total", f"{total_revenue:,.0f} Ar")
            
            with col3:
                has_sales = sales_data is not None and not sales_data.empty
                if has_sales:
                    sd = st.session_state.get('sales_processed', sales_data).copy()
                    unit_cols = [c for c in sd.columns if c in ['unit_price', 'price', 'prix']]
                    qty_cols = [c for c in sd.columns if c in ['quantity', 'qty', 'quantite', 'quantit√©']]
                    qt = pd.Series(0, index=sd.index)
                    if qty_cols:
                        qt = pd.to_numeric(sd[qty_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(0)
                    if unit_cols:
                        up = pd.to_numeric(sd[unit_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(float(default_unit_price))
                    else:
                        up = pd.Series(float(default_unit_price), index=sd.index)
                    if 'total_amount' not in sd.columns:
                        sd['total_amount'] = (up * qt)
                    else:
                        ta_clean = pd.to_numeric(
                            sd['total_amount'].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'),
                            errors='coerce'
                        )
                        fill_series = (up * qt)
                        sd['total_amount'] = ta_clean.where(ta_clean.notna() & (ta_clean > 0), fill_series)
                    total_amount_series = pd.to_numeric(sd['total_amount'], errors='coerce').fillna(0)
                    avg_order = total_amount_series.mean()
                    if pd.isna(avg_order):
                        avg_order = 0
                    st.metric("üõí Panier Moyen", f"{avg_order:,.0f} Ar")
                else:
                    st.metric("üõí Panier Moyen", "N/A")
                    st.caption("Ventes indisponibles ou colonne 'total_amount' manquante")
            
            with col4:
                has_sales = sales_data is not None and not sales_data.empty
                if has_sales and 'order_id' in sales_data.columns:
                    total_orders = sales_data['order_id'].nunique()
                else:
                    total_orders = len(sales_data) if has_sales else 0
                st.metric("üì¶ Commandes", f"{total_orders:,}")
            
            with col5:
                if not marketing_data.empty and 'cost' in marketing_data.columns:
                    total_marketing_cost = marketing_data['cost'].sum()
                    st.metric("üì¢ Co√ªt Marketing", f"{total_marketing_cost:,.0f} Ar")
                else:
                    st.metric("üì¢ Co√ªt Marketing", "N/A")
            
            with col6:
                if marketing_data.empty:
                    st.metric("üìà ROI Marketing", "N/A")
                    st.caption("Donn√©es marketing indisponibles")
                elif 'cost' not in marketing_data.columns:
                    st.metric("üìà ROI Marketing", "N/A")
                    st.caption("Colonne 'cost' manquante dans marketing")
                else:
                    # Nettoyage num√©rique du cost
                    cost_series = pd.to_numeric(
                        marketing_data['cost'].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'),
                        errors='coerce'
                    ).fillna(0)
                    total_cost = float(cost_series.sum())
                    # Source de revenus pour ROI: priorit√© √† marketing.revenue si disponible sinon CA ventes
                    if 'revenue' in marketing_data.columns:
                        rev_series = pd.to_numeric(
                            marketing_data['revenue'].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'),
                            errors='coerce'
                        ).fillna(0)
                        roi_revenue = float(rev_series.sum())
                    else:
                        roi_revenue = float(total_revenue)
                    if total_cost == 0 and roi_revenue > 0:
                        st.metric("üìà ROI Marketing", "‚àû")
                        st.caption("Co√ªt marketing nul, CA > 0")
                    elif total_cost == 0 and roi_revenue == 0:
                        st.metric("üìà ROI Marketing", "N/A")
                        st.caption("Co√ªt et CA nuls")
                    elif roi_revenue == 0:
                        st.metric("üìà ROI Marketing", "0.0x")
                        st.caption("CA = 0")
                    else:
                        marketing_roi = roi_revenue / total_cost
                        st.metric("üìà ROI Marketing", f"{marketing_roi:.1f}x")
            
            st.markdown("---")
            
            # Section 1: Analyse des Ventes
            has_sales = sales_data is not None and not sales_data.empty
            if has_sales:
                st.subheader("üìä Analyse des Ventes")
                
                col1, col2 = st.columns(2)
                
                with st.expander("üß™ Diagnostics KPIs (CA & Panier)", expanded=False):
                    try:
                        dbg = sales_data.copy()
                        unit_cols = [c for c in dbg.columns if c in ['unit_price', 'price', 'prix']]
                        qty_cols = [c for c in dbg.columns if c in ['quantity', 'qty', 'quantite', 'quantit√©']]
                        qty_series = pd.to_numeric(dbg[qty_cols[0]], errors='coerce') if qty_cols else pd.Series([], dtype=float)
                        st.caption(f"Lignes ventes: {len(dbg)} | Colonne quantit√©: {qty_cols[0] if qty_cols else '‚Äî'} | Somme quantit√©s: {float(qty_series.fillna(0).sum()) if not qty_series.empty else 0}")
                        st.caption(f"Prix unitaire par d√©faut: {float(default_unit_price):,.0f} Ar")
                        # Reconstitution rapide
                        if unit_cols:
                            up = pd.to_numeric(dbg[unit_cols[0]].astype(str).str.replace(r"[^0-9,.-]","", regex=True).str.replace(',','.'), errors='coerce').fillna(float(default_unit_price))
                        else:
                            up = pd.Series(float(default_unit_price), index=dbg.index)
                        qt = pd.to_numeric(dbg[qty_cols[0]].astype(str).str.replace(r"[^0-9,.-]","", regex=True).str.replace(',','.'), errors='coerce').fillna(0) if qty_cols else pd.Series(0, index=dbg.index)
                        if 'total_amount' in dbg.columns:
                            ta_clean = pd.to_numeric(dbg['total_amount'].astype(str).str.replace(r"[^0-9,.-]","", regex=True).str.replace(',','.'), errors='coerce')
                            dbg['__ta'] = ta_clean.where(ta_clean.notna() & (ta_clean > 0), up*qt)
                        else:
                            dbg['__ta'] = up*qt
                        st.caption(f"Somme total_amount (apr√®s nettoyage/reconstruction): {float(pd.to_numeric(dbg['__ta'], errors='coerce').fillna(0).sum()):,.0f} Ar")
                        st.dataframe(dbg[['customer_id', qty_cols[0] if qty_cols else None, unit_cols[0] if unit_cols else None, '__ta']].head(5))
                    except Exception as e:
                        st.caption(f"Diagnostics indisponible: {str(e)}")

                has_sales = not sales_data.empty if sales_data is not None else False
                if has_sales:
                    # Utiliser sales_processed si disponible, sinon utiliser sales_data
                    sp = st.session_state.get('sales_processed', sales_data)
                    if 'order_date' in sp.columns and not sp.empty:
                        daily_sales = sp.groupby(sp['order_date'].dt.date)['total_amount'].sum().reset_index()
                        
                        fig_sales_trend = px.line(
                            daily_sales,
                            x='order_date',
                            y='total_amount',
                            title='√âvolution du Chiffre d\'Affaires'
                        )
                        st.plotly_chart(fig_sales_trend, use_container_width=True)
                
                with col2:
                    # Top produits
                    if 'product_id' in sales_data.columns:
                        top_products = sales_data.groupby('product_id')['total_amount'].sum().nlargest(10)
                        
                        fig_top_products = px.bar(
                            x=top_products.values,
                            y=top_products.index,
                            orientation='h',
                            title='Top 10 Produits par CA'
                        )
                        st.plotly_chart(fig_top_products, use_container_width=True)
            
            # Section 2: Segmentation Clients
            if not segments_data.empty:
                st.subheader("üë• Segmentation Clients")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Distribution des segments
                    segment_counts = segments_data['cluster'].value_counts()
                    fig_segments = px.pie(
                        values=segment_counts.values,
                        names=[f'Segment {i}' for i in segment_counts.index],
                        title='Distribution des Segments'
                    )
                    st.plotly_chart(fig_segments, use_container_width=True)
                
                with col2:
                    # RFM par segment
                    rfm_by_segment = segments_data.groupby('cluster')[['recency', 'frequency', 'monetary']].mean()
                    
                    fig_rfm = px.bar(
                        rfm_by_segment.reset_index(),
                        x='cluster',
                        y=['recency', 'frequency', 'monetary'],
                        title='Profil RFM par Segment',
                        barmode='group'
                    )
                    st.plotly_chart(fig_rfm, use_container_width=True)
            
            # Section 3: Performance Marketing
            if not marketing_data.empty:
                st.subheader("üì¢ Performance Marketing")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # KPIs Marketing par p√©riode
                    if 'date' in marketing_data.columns:
                        marketing_data['date'] = pd.to_datetime(marketing_data['date'])
                        marketing_timeline = marketing_data.groupby(marketing_data['date'].dt.date).agg({
                            'impressions': 'sum',
                            'clicks': 'sum',
                            'cost': 'sum'
                        }).reset_index()
                        
                        marketing_timeline['ctr'] = marketing_timeline['clicks'] / marketing_timeline['impressions']
                        
                        fig_marketing = px.line(
                            marketing_timeline,
                            x='date',
                            y='ctr',
                            title='√âvolution du CTR'
                        )
                        st.plotly_chart(fig_marketing, use_container_width=True)
                
                with col2:
                    # Performance par canal
                    if 'channel' in marketing_data.columns:
                        channel_perf = marketing_data.groupby('channel').agg({
                            'impressions': 'sum',
                            'clicks': 'sum',
                            'cost': 'sum'
                        }).reset_index()
                        
                        fig_channels = px.bar(
                            channel_perf,
                            x='channel',
                            y='clicks',
                            title='Clics par Canal'
                        )
                        st.plotly_chart(fig_channels, use_container_width=True)
            
            # Section 4: Analyse G√©ographique
            if not customers_data.empty and 'city' in customers_data.columns:
                st.subheader("üåç R√©partition G√©ographique")
                
                city_stats = customers_data['city'].value_counts().head(10)
                fig_geo = px.bar(
                    x=city_stats.values,
                    y=city_stats.index,
                    orientation='h',
                    title='Top 10 Villes'
                )
                st.plotly_chart(fig_geo, use_container_width=True)
            
            # Section 4b: Segmentation D√©mographique (√Çge, Genre, Ville)
            if not customers_data.empty and not sales_data.empty:
                available_demo = [c for c in ['age', 'gender', 'city'] if c in customers_data.columns]
                if available_demo:
                    st.subheader("üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Segmentation D√©mographique")
                    try:
                        has_sales = not sales_data.empty if sales_data is not None else False
                        if has_sales and customers_data is not None and not customers_data.empty:
                            # Fusion ventes + clients pour KPIs par segment
                            sp = st.session_state.get('sales_processed', sales_data)
                            sales_demo = sp.merge(
                                customers_data[['customer_id'] + available_demo], on='customer_id', how='left'
                            )
                        else:
                            raise ValueError("Donn√©es de vente ou clients manquantes")
                        # Reconstruire/Nettoyer total_amount avec le m√™me algorithme que les KPIs
                        unit_cols = [c for c in sales_demo.columns if c in ['unit_price', 'price', 'prix']]
                        qty_cols = [c for c in sales_demo.columns if c in ['quantity', 'qty', 'quantite', 'quantit√©']]
                        qt = pd.Series(0, index=sales_demo.index)
                        if qty_cols:
                            qt = pd.to_numeric(sales_demo[qty_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(0)
                        if unit_cols:
                            up = pd.to_numeric(sales_demo[unit_cols[0]].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'), errors='coerce').fillna(float(default_unit_price))
                        else:
                            up = pd.Series(float(default_unit_price), index=sales_demo.index)
                        if 'total_amount' not in sales_demo.columns:
                            sales_demo['total_amount'] = (up * qt)
                        else:
                            ta_clean = pd.to_numeric(
                                sales_demo['total_amount'].astype(str).str.replace(r"[^0-9,.-]", "", regex=True).str.replace(',', '.'),
                                errors='coerce'
                            )
                            sales_demo['total_amount'] = ta_clean.where(ta_clean.notna() & (ta_clean > 0), (up * qt))
                        # Tranches d'√¢ge
                        if 'age' in available_demo:
                            sales_demo['age'] = pd.to_numeric(sales_demo['age'], errors='coerce').fillna(30)
                            bins = [0, 17, 24, 34, 44, 54, 64, 150]
                            labels = ['0-17', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']
                            sales_demo['age_band'] = pd.cut(sales_demo['age'], bins=bins, labels=labels, right=True)
                        # KPIs par √¢ge
                        if 'age_band' in sales_demo.columns:
                            age_kpi = sales_demo.groupby('age_band').agg(
                                clients=('customer_id', 'nunique'),
                                ca=('total_amount', 'sum'),
                                commandes=('customer_id', 'count')
                            ).reset_index()
                            age_kpi['panier_moyen'] = (age_kpi['ca'] / age_kpi['commandes']).replace([np.inf, -np.inf], 0).fillna(0)
                            colA, colB = st.columns(2)
                            with colA:
                                fig_age_ca = px.bar(age_kpi, x='age_band', y='ca', title='CA par tranche d\'√¢ge (Ar)')
                                st.plotly_chart(fig_age_ca, use_container_width=True)
                            with colB:
                                fig_age_pm = px.bar(age_kpi, x='age_band', y='panier_moyen', title='Panier Moyen par tranche d\'√¢ge (Ar)')
                                st.plotly_chart(fig_age_pm, use_container_width=True)
                        # KPIs par genre
                        if 'gender' in available_demo:
                            gender_kpi = sales_demo.groupby('gender').agg(
                                clients=('customer_id', 'nunique'),
                                ca=('total_amount', 'sum')
                            ).reset_index()
                            fig_gender = px.bar(gender_kpi, x='gender', y='ca', title='CA par genre (Ar)')
                            st.plotly_chart(fig_gender, use_container_width=True)
                        # KPIs par ville (Top 10)
                        if 'city' in available_demo:
                            city_kpi = sales_demo.groupby('city')['total_amount'].sum().sort_values(ascending=False).head(10)
                            fig_city_rev = px.bar(x=city_kpi.values, y=city_kpi.index, orientation='h', title='Top 10 Villes par CA (Ar)')
                            st.plotly_chart(fig_city_rev, use_container_width=True)
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Segmentation d√©mographique indisponible: {str(e)}")

            # Section 5: Alertes et Recommandations
            st.subheader("üö® Alertes et Recommandations")
            
            alerts = []
            recommendations = []
            
            # Analyse des tendances
            has_sales = sales_data is not None and not sales_data.empty and 'order_date' in sales_data.columns
            if has_sales:
                # S'assurer que les dates sont au format datetime
                sales_data['order_date'] = pd.to_datetime(sales_data['order_date'], errors='coerce')
                # Supprimer les lignes avec des dates invalides
                valid_dates = sales_data.dropna(subset=['order_date'])
                if not valid_dates.empty:
                    max_date = valid_dates['order_date'].max()
                    recent_sales = valid_dates[valid_dates['order_date'] >= (max_date - pd.Timedelta(days=7))]
                    previous_sales = valid_dates[(valid_dates['order_date'] >= (max_date - pd.Timedelta(days=14))) & 
                                               (valid_dates['order_date'] < (max_date - pd.Timedelta(days=7)))]
                else:
                    recent_sales = pd.DataFrame()
                    previous_sales = pd.DataFrame()
                
                if len(recent_sales) > 0 and len(previous_sales) > 0:
                    recent_avg = recent_sales['total_amount'].mean()
                    previous_avg = previous_sales['total_amount'].mean()
                    change = (recent_avg - previous_avg) / previous_avg * 100
                    
                    if change < -10:
                        alerts.append("üî¥ Baisse significative du panier moyen (-{:.1f}%)".format(abs(change)))
                        recommendations.append("Analyser les causes de la baisse et lancer une campagne de stimulation")
                    elif change > 10:
                        alerts.append("üü¢ Hausse significative du panier moyen (+{:.1f}%)".format(change))
                        recommendations.append("Capitaliser sur cette tendance positive")
            
            # Alertes sur les co√ªts marketing
            if not marketing_data.empty and 'cpc' in marketing_data.columns:
                avg_cpc = marketing_data['cpc'].mean()
                if avg_cpc > analytics.targets['cpc_max']:
                    alerts.append(f"üî¥ CPC √©lev√©: {avg_cpc:.0f} Ar (objectif: {analytics.targets['cpc_max']:.0f} Ar)")
                    recommendations.append("Optimiser le ciblage et revoir la strat√©gie d'ench√®res")
            
            # Affichage des alertes
            if alerts:
                st.write("**üö® Alertes:**")
                for alert in alerts:
                    st.warning(alert)
            
            if recommendations:
                st.write("**üí° Recommandations:**")
                for rec in recommendations:
                    st.info(rec)
            
            if not alerts and not recommendations:
                st.success("‚úÖ Aucune alerte. Toutes les m√©triques sont dans les objectifs!")

        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement du dashboard: {str(e)}")

    # Module Rapport Final
    elif selected_tab == "üìë Rapport Final":
        st.header("üìë Rapport Final - Analyse Compl√®te TeeTech")
        
        if st.button("üìã G√©n√©rer le Rapport Complet", type="primary"):
            with st.spinner("G√©n√©ration du rapport en cours..."):
                try:
                    # Chargement de toutes les donn√©es
                    customers_data = pd.read_csv('output/customers_clean.csv') if os.path.exists('output/customers_clean.csv') else pd.DataFrame()
                    sales_data = pd.read_csv('output/sales_clean.csv') if os.path.exists('output/sales_clean.csv') else pd.DataFrame()
                    marketing_data = pd.read_csv('output/marketing_clean.csv') if os.path.exists('output/marketing_clean.csv') else pd.DataFrame()
                    segments_data = pd.read_csv('output/customer_segments.csv') if os.path.exists('output/customer_segments.csv') else pd.DataFrame()
                    
                    # Calcul des personas et KPIs
                    personas = {}
                    kpi_summary = {}
                    churn_data = None
                    
                    if not segments_data.empty and not customers_data.empty and not sales_data.empty:
                        try:
                            products_data = pd.read_csv('output/products_clean.csv')
                        except:
                            products_data = pd.DataFrame()
                        
                        personas = analytics.create_customer_personas(segments_data, customers_data, sales_data, products_data)
                    
                    if not marketing_data.empty:
                        st.caption("[Rapport] Aper√ßu marketing dtypes et √©chantillon")
                        try:
                            st.write(marketing_data.dtypes.astype(str))
                            st.write(marketing_data.head(3))
                        except Exception:
                            pass
                        try:
                            _, kpi_summary, _ = analytics.calculate_marketing_kpis(marketing_data)
                            # V√©rifier types du r√©sum√©
                            if kpi_summary is not None:
                                ks_debug = {k: (type(v).__name__, v) for k, v in kpi_summary.items()}
                                st.caption("[Rapport] kpi_summary types")
                                st.write(ks_debug)
                        except Exception as e:
                            st.error(f"[Rapport] Erreur calcul KPIs marketing: {str(e)}")
                            raise
                    
                    if not customers_data.empty and not sales_data.empty:
                        churn_data, _, _ = analytics.build_predictive_model(customers_data, sales_data)
                    
                    # G√©n√©ration du rapport
                    report_content = analytics.generate_comprehensive_report(
                        customers_data, sales_data, marketing_data, 
                        segments_data, personas, kpi_summary, churn_data
                    )
                    
                    st.success("‚úÖ Rapport g√©n√©r√© avec succ√®s!")
                    
                    # Affichage du rapport
                    st.markdown("---")
                    st.markdown(report_content)
                    
                    # Options de t√©l√©chargement
                    st.markdown("---")
                    st.subheader("‚¨áÔ∏è T√©l√©chargements")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        # Rapport Markdown
                        st.download_button(
                            "üìÑ Rapport Markdown",
                            report_content,
                            "rapport_teetech_complet.md",
                            "text/markdown"
                        )
                    
                    with col2:
                        # Donn√©es compil√©es
                        if not customers_data.empty and not sales_data.empty:
                            # Cr√©ation d'un dataset consolid√©
                            consolidated_data = sales_data.merge(
                                customers_data[['customer_id', 'age', 'city']], 
                                on='customer_id', 
                                how='left'
                            )
                            
                            consolidated_csv = consolidated_data.to_csv(index=False)
                            st.download_button(
                                "üìä Donn√©es Consolid√©es",
                                consolidated_csv,
                                "donnees_consolidees.csv",
                                "text/csv"
                            )
                    
                    with col3:
                        # Package complet (ZIP)
                        if st.button("üì¶ Package Complet (.zip)"):
                            # Cr√©ation d'un fichier ZIP avec tous les outputs
                            zip_buffer = io.BytesIO()
                            
                            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                # Ajouter le rapport
                                zip_file.writestr("rapport_complet.md", report_content)
                                
                                # Ajouter tous les fichiers CSV de output/
                                output_files = glob.glob('output/*.csv')
                                for file_path in output_files:
                                    filename = os.path.basename(file_path)
                                    with open(file_path, 'r', encoding='utf-8') as f:
                                        zip_file.writestr(f"data/{filename}", f.read())
                                
                                # Ajouter les visualisations PNG s'il y en a
                                viz_files = glob.glob('output/*.png')
                                for file_path in viz_files:
                                    filename = os.path.basename(file_path)
                                    with open(file_path, 'rb') as f:
                                        zip_file.writestr(f"visualizations/{filename}", f.read())
                            
                            zip_buffer.seek(0)
                            
                            st.download_button(
                                "üì¶ T√©l√©charger Package",
                                zip_buffer.getvalue(),
                                "teetech_analytics_package.zip",
                                "application/zip"
                            )
                    
                    # R√©sum√© ex√©cutif visuel
                    st.markdown("---")
                    st.subheader("üìà R√©sum√© Ex√©cutif Visuel")
                    
                    # M√©triques cl√©s
                    if not customers_data.empty or not sales_data.empty:
                        summary_cols = st.columns(4)
                        
                        with summary_cols[0]:
                            total_customers = len(customers_data) if not customers_data.empty else 0
                            st.metric("üë• Clients Total", f"{total_customers:,}")
                        
                        with summary_cols[1]:
                            has_sales = sales_data is not None and not sales_data.empty
                            total_revenue = sales_data['total_amount'].sum() if has_sales and 'total_amount' in sales_data.columns else 0
                            st.metric("üí∞ CA Total", f"{total_revenue:,.0f} Ar")
                        
                        with summary_cols[2]:
                            num_segments = segments_data['cluster'].nunique() if not segments_data.empty else 0
                            st.metric("üéØ Segments", f"{num_segments}")
                        
                        with summary_cols[3]:
                            if churn_data is not None:
                                high_risk = len(churn_data[churn_data['churn_risk'] == '√âlev√©'])
                                st.metric("‚ö†Ô∏è Risque Churn", f"{high_risk}")
                            else:
                                st.metric("‚ö†Ô∏è Risque Churn", "N/A")
                    
                    # Graphiques de synth√®se
                    if not segments_data.empty:
                        # Valeur par segment
                        segment_value = segments_data.groupby('cluster')['monetary'].mean()
                        fig_segment_summary = px.bar(
                            x=[f'Segment {i}' for i in segment_value.index],
                            y=segment_value.values,
                            title='Valeur Moyenne par Segment Client',
                            labels={'x': 'Segments', 'y': 'Valeur Moyenne (Ar)'}
                        )
                        st.plotly_chart(fig_segment_summary, use_container_width=True)
                    
                    # Recommandations prioritaires
                    st.markdown("---")
                    st.subheader("üéØ Recommandations Prioritaires")
                    
                    priority_recs = [
                        "üî¥ **Urgent**: Mettre en place un programme de r√©tention pour les clients √† risque √©lev√©",
                        "üü° **Court terme**: Optimiser les campagnes marketing sous-performantes (CPC > objectif)",
                        "üü¢ **Moyen terme**: D√©velopper des offres personnalis√©es par segment client",
                        "üîµ **Long terme**: Investir dans l'automatisation du marketing pour am√©liorer l'efficacit√©"
                    ]
                    
                    for rec in priority_recs:
                        st.write(rec)
                    
                    # ROI estim√© des recommandations
                    st.markdown("---")
                    st.subheader("üíπ ROI Estim√© des Recommandations")
                    
                    roi_estimates = [
                        {"Action": "Programme de r√©tention", "Investissement": "100,000 Ar", "ROI Attendu": "300%", "D√©lai": "3 mois"},
                        {"Action": "Optimisation marketing", "Investissement": "50,000 Ar", "ROI Attendu": "200%", "D√©lai": "1 mois"},
                        {"Action": "Personnalisation", "Investissement": "200,000 Ar", "ROI Attendu": "400%", "D√©lai": "6 mois"},
                        {"Action": "Automatisation", "Investissement": "500,000 Ar", "ROI Attendu": "500%", "D√©lai": "12 mois"}
                    ]
                    
                    roi_df = pd.DataFrame(roi_estimates)
                    st.dataframe(roi_df, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la g√©n√©ration du rapport: {str(e)}")
                    st.error("Assurez-vous d'avoir ex√©cut√© les modules pr√©c√©dents.")
        
        # Aper√ßu des donn√©es disponibles
        st.markdown("---")
        st.subheader("üìÇ Donn√©es Disponibles pour le Rapport")
        
        data_status = [
            {"Module": "M2 - Nettoyage", "Statut": "‚úÖ" if os.path.exists('output/customers_clean.csv') else "‚ùå"},
            {"Module": "M3 - Segmentation", "Statut": "‚úÖ" if os.path.exists('output/customer_segments.csv') else "‚ùå"},
            {"Module": "M4 - Personas", "Statut": "‚úÖ" if os.path.exists('output/customer_segments.csv') else "‚ùå"},
            {"Module": "M5 - KPIs Marketing", "Statut": "‚úÖ" if os.path.exists('output/campaign_kpis.csv') else "‚ùå"},
            {"Module": "M6 - Pr√©dictif", "Statut": "‚úÖ" if os.path.exists('output/churn_predictions.csv') else "‚ùå"}
        ]
        
        status_df = pd.DataFrame(data_status)
        st.dataframe(status_df, use_container_width=True)
        
        if status_df["Statut"].str.contains("‚ùå").any():
            st.warning("‚ö†Ô∏è Certains modules n'ont pas √©t√© ex√©cut√©s. Le rapport sera incomplet.")
            st.info("üí° Ex√©cutez tous les modules pour obtenir un rapport complet.")

if __name__ == "__main__":
    main()